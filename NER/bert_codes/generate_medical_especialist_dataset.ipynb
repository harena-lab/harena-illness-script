{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else os.getcwd())\n",
    "\n",
    "filepath = 'annotations-medical_specialist-dpoc-bio-composed-multiple.jsonl'\n",
    "raw_dataset = pd.read_json(filepath, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_filepath = 'test_data_info_with_metrics.csv'\n",
    "segment_dataset = pd.read_csv(segment_filepath)\n",
    "segment_dataset = segment_dataset['doc_id']\n",
    "segment_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset = raw_dataset[raw_dataset['doc_id'].isin(segment_dataset)]\n",
    "filtered_dataset.reset_index(drop=True, inplace=True)\n",
    "filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset = filtered_dataset[['doc_id', 'text', 'labels']]\n",
    "filtered_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.DataFrame()\n",
    "raw_df[\"doc_id\"] = filtered_dataset[\"doc_id\"]\n",
    "raw_df[\"text\"] = filtered_dataset[\"text\"]\n",
    "\n",
    "full_tokens = []\n",
    "\n",
    "for index, row in filtered_dataset.iterrows():\n",
    "    tokens = []\n",
    "    for element in filtered_dataset.iloc[index]['labels']:\n",
    "        tokens.append(element[0])\n",
    "    full_tokens.append(tokens)\n",
    "    \n",
    "raw_df['tokens'] = full_tokens\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base2(n):\n",
    "    return 2**n\n",
    "\n",
    "tags = {'O': 0,\n",
    "            'B-pathophysiology': base2(0), \n",
    "            \"I-pathophysiology\": base2(1), \n",
    "            \"B-epidemiology\": base2(2), \n",
    "            \"I-epidemiology\": base2(3),\n",
    "            \"B-etiology\": base2(4),\n",
    "            \"I-etiology\": base2(5),\n",
    "            \"B-history\": base2(6),\n",
    "            \"I-history\": base2(7),\n",
    "            \"B-physical\": base2(8),\n",
    "            \"I-physical\": base2(9),\n",
    "            \"B-exams\": base2(10),\n",
    "            \"I-exams\": base2(11),\n",
    "            \"B-differential\": base2(12),\n",
    "            \"I-differential\": base2(13),\n",
    "            \"B-therapeutic\": base2(14),\n",
    "            \"I-therapeutic\": base2(15)\n",
    "           }\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags_aux = {'O': 0}\n",
    "\n",
    "cats = [\"Pathophysiology\", \n",
    "        \"Epidemiology\", \n",
    "        \"Etiology\", \n",
    "        \"History\", \n",
    "        \"Physical_examination\", \n",
    "        \"Complementary_exams\",\n",
    "        \"Differential_diagnosis\",\n",
    "        \"Therapeutic_plan\"\n",
    "       ]\n",
    "\n",
    "for i in range(len(cats)):\n",
    "    ner_tags_aux[\"B-\" + cats[i]] = base2(2*i)\n",
    "    ner_tags_aux[\"I-\" + cats[i]] = base2(2*i+1)\n",
    "    for j in range(i+1, len(cats)):\n",
    "        ner_tags_aux[\"B-\" + cats[i] + '-' + cats[j]] = base2(2*i) + base2(2*j)\n",
    "        ner_tags_aux[\"I-\" + cats[i] + '-' + cats[j]] = base2(2*i+1) + base2(2*j+1)\n",
    "        for k in range(j+1, len(cats)):\n",
    "            ner_tags_aux[\"B-\" + cats[i] + '-' + cats[j] + '-' + cats[k]] = base2(2*i) + base2(2*j) + base2(2*k)\n",
    "            ner_tags_aux[\"I-\" + cats[i] + '-' + cats[j] + '-' + cats[k]] = base2(2*i+1) + base2(2*j+1) + base2(2*k+1)\n",
    "            \n",
    "ner_tags_aux['B-Pathophysiology-Epidemiology-Etiology-History'] = 85\n",
    "ner_tags_aux['I-Pathophysiology-Epidemiology-Etiology-History'] = 170\n",
    "\n",
    "tags_ner = [k for k, v in ner_tags_aux.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_ner_aux = {value: key for key, value in ner_tags_aux.items()}\n",
    "ner_tags = {key: index for index, key in enumerate(ner_tags_aux.keys())}\n",
    "ner_tags_inverted = {value: key for key, value in ner_tags.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tags_inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anotation2number(anotation):\n",
    "    if anotation[3] == \"O\":\n",
    "        return 0\n",
    "    start = anotation[3]\n",
    "    labels = anotation[4]\n",
    "    valor = 0\n",
    "    for label in labels:\n",
    "        valor += tags[start+\"-\"+label]\n",
    "    valor = ner_tags[tags_ner_aux[valor]]\n",
    "    return valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_labels = []\n",
    "\n",
    "for index, row in filtered_dataset.iterrows():\n",
    "    labels = []\n",
    "    for element in filtered_dataset.iloc[index]['labels']:\n",
    "        if element[3] == 'O':\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(anotation2number(element))\n",
    "    full_labels.append(labels)\n",
    "    \n",
    "raw_df['ner_ids'] = full_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_data_filepath = 'aligned_annotations-dpoc-medical_specialist_metrics_435.csv'\n",
    "year_data = pd.read_csv(year_data_filepath)\n",
    "year_data = year_data[['annotation id', 'year']]\n",
    "year_data.rename(columns={'annotation id': 'doc_id'}, inplace=True)\n",
    "\n",
    "semester_distribution = year_data['year'].value_counts()\n",
    "semester_distribution.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.merge(raw_df, year_data, on='doc_id')\n",
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Year distribution:\\n\", year_data['year'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into train and temp (60% train, 40% temp)\n",
    "train_df, temp_df = train_test_split(total_data, test_size=0.4, stratify=total_data['year'], random_state=42)\n",
    "\n",
    "# Split the temp data into validation and test (50% validation, 50% test of the temp data)\n",
    "validation_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['year'], random_state=42)\n",
    "\n",
    "# Check the distribution of the 'year' column in each dataset\n",
    "print(\"Train distribution:\\n\", train_df['year'].value_counts(normalize=True))\n",
    "print(\"Validation distribution:\\n\", validation_df['year'].value_counts(normalize=True))\n",
    "print(\"Test distribution:\\n\", test_df['year'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict, ClassLabel, Sequence\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "validation_dataset = Dataset.from_pandas(validation_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_class_labels = ClassLabel(num_classes = len(tags_ner),names=tags_ner)\n",
    "\n",
    "train_dataset = train_dataset.cast_column(\"ner_ids\", Sequence(ner_class_labels))\n",
    "validation_dataset = validation_dataset.cast_column(\"ner_ids\", Sequence(ner_class_labels))\n",
    "test_dataset = test_dataset.cast_column(\"ner_ids\", Sequence(ner_class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': validation_dataset,\n",
    "    'test': test_dataset})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Assuming `dataset` is your DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": dataset[\"train\"].remove_columns([\"__index_level_0__\",'year']),\n",
    "    \"validation\": dataset[\"validation\"].remove_columns([\"__index_level_0__\",'year']),\n",
    "    \"test\": dataset[\"test\"].remove_columns([\"__index_level_0__\",'year']),\n",
    "})\n",
    "\n",
    "# Check the modified dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_hub(\"GLeite/BioBert-dpoc-medical_specialist-multiple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
