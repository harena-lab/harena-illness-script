{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e3082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metrics_all = {'Human_84': pd.read_csv('medical_specialist/annotations-dpoc-medical_specialist_metrics_86.csv'),\n",
    "               'Human_435': pd.read_csv('medical_specialist/aligned_annotations-dpoc-medical_specialist_metrics_435.csv'),\n",
    "               'BioBERT': pd.read_csv('biobert_balanced/annotations-dpoc-biobert_metrics.csv'),\n",
    "               'BioBERT_Llama': pd.read_csv('biobert-llama_balanced/annotations-dpoc-biobert-llama_metrics.csv'),\n",
    "               'Llama': pd.read_csv('llama/annotations-dpoc-llm_10_tf_idf_custom_shot_metrics.csv'),\n",
    "            #    'Llama_aug': pd.read_csv('llama/annotations-dpoc-llm_augmented_10_tf_idf_custom_shot_metrics.csv')\n",
    "               'Llama_aug': pd.read_csv('llama/annotations-dpoc-llm_10_tf_idf_custom_shot_metrics.csv')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba5a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os # Import os to check for file existence\n",
    "import numpy as np # Import numpy for calculations\n",
    "\n",
    "def calculate_correlations(metrics_dict):\n",
    "    \"\"\"\n",
    "    Calculates the Pearson correlation between the *biannual year* (1-2, 3-4, 5-6) of the student and 'cluster membership' \n",
    "    for each DataFrame in the input dictionary.\n",
    "\n",
    "    Args:\n",
    "        metrics_dict (dict): A dictionary where keys are approach names (str)\n",
    "                             and values are pandas DataFrames.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are the approach names and values\n",
    "              are the calculated correlation coefficients. If columns\n",
    "              are missing for an approach, the value will be None.\n",
    "    \"\"\"\n",
    "    correlations = {}\n",
    "    \n",
    "    # Define the column names we need\n",
    "    year_col = 'year'\n",
    "    cluster_col = 'cluster kmeans 3 cat'\n",
    "\n",
    "    for approach_name, df in metrics_dict.items():\n",
    "        print(f\"--- Processing: {approach_name} ---\")\n",
    "        \n",
    "        # Check if the required columns exist in the DataFrame\n",
    "        if year_col in df.columns and cluster_col in df.columns:\n",
    "            try:\n",
    "                # Calculate the Pearson correlation coefficient\n",
    "                # Ensure data is numeric before calculating correlation\n",
    "                year_data = pd.to_numeric(df[year_col], errors='coerce')\n",
    "                cluster_data = pd.to_numeric(df[cluster_col], errors='coerce')\n",
    "                \n",
    "                # --- NEW: Map years to biannual groups (1,2)->1, (3,4)->2, (5,6)->3 ---\n",
    "                biannual_year_data = np.ceil(year_data / 2)\n",
    "                \n",
    "                # Drop rows where data could not be coerced to numeric\n",
    "                valid_data = pd.DataFrame({'biannual_year': biannual_year_data, 'cluster': cluster_data}).dropna()\n",
    "                \n",
    "                if not valid_data.empty:\n",
    "                    # Calculate Pearson correlation (default, but explicitly stated)\n",
    "                    corr = valid_data['biannual_year'].corr(valid_data['cluster'], method='pearson')\n",
    "                    correlations[approach_name] = corr\n",
    "                    print(f\"Biannual Correlation: {corr}\")\n",
    "                else:\n",
    "                    print(f\"No valid numeric data to correlate after cleaning.\")\n",
    "                    correlations[approach_name] = None\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating correlation for {approach_name}: {e}\")\n",
    "                correlations[approach_name] = None\n",
    "        else:\n",
    "            print(f\"Skipping {approach_name}: Missing required columns.\")\n",
    "            if year_col not in df.columns:\n",
    "                print(f\"  Missing column: '{year_col}'\")\n",
    "            if cluster_col not in df.columns:\n",
    "                print(f\"  Missing column: '{cluster_col}'\")\n",
    "            correlations[approach_name] = None\n",
    "            \n",
    "    return correlations\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # This block will only run when the script is executed directly\n",
    "    \n",
    "    # Define the file paths\n",
    "    file_paths = {\n",
    "        'Human_84': 'medical_specialist/annotations-dpoc-medical_specialist_metrics_84.csv',\n",
    "        'Human_435': 'medical_specialist/aligned_annotations-dpoc-medical_specialist_metrics_435.csv',\n",
    "        'BioBERT': 'biobert_balanced/annotations-dpoc-biobert_metrics.csv',\n",
    "        'BioBERT_Llama': 'biobert-llama_balanced/annotations-dpoc-biobert-llama_metrics.csv',\n",
    "        'Llama': 'llama/annotations-dpoc-llm_10_tf_idf_custom_shot_metrics.csv',\n",
    "    }\n",
    "    \n",
    "    metrics_all = {}\n",
    "    \n",
    "    print(\"Loading CSV files...\")\n",
    "    # Load dataframes, handling potential FileNotFoundError\n",
    "    for name, path in file_paths.items():\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                metrics_all[name] = pd.read_csv(path)\n",
    "                print(f\"Successfully loaded: {path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {path}: {e}\")\n",
    "                metrics_all[name] = pd.DataFrame() # Add empty df to avoid errors later\n",
    "        else:\n",
    "            print(f\"File not found: {path}. Skipping '{name}'.\")\n",
    "            # Create mock data if files don't exist, so the function can be tested\n",
    "            print(f\"Creating mock data for '{name}' for demonstration.\")\n",
    "            # Updated mock data to include years 5 & 6\n",
    "            metrics_all[name] = pd.DataFrame({\n",
    "                'year of the student': [1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 3, 5],\n",
    "                'cluster membership': [0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0],\n",
    "                'other_data': ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm']\n",
    "            })\n",
    "\n",
    "    # Check if we have any data to process\n",
    "    if metrics_all:\n",
    "        # Calculate the correlations\n",
    "        all_correlations = calculate_correlations(metrics_all)\n",
    "        \n",
    "        print(\"\\n--- Final Correlation Results ---\")\n",
    "        for approach, corr_value in all_correlations.items():\n",
    "            if corr_value is not None:\n",
    "                print(f\"{approach}: {corr_value:.4f}\")\n",
    "            else:\n",
    "                print(f\"{approach}: Calculation failed or columns missing\")\n",
    "    else:\n",
    "        print(\"\\nNo data was loaded. Please check your file paths.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a480b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os # Import os to check for file existence\n",
    "import numpy as np # Import numpy for calculations\n",
    "import matplotlib.pyplot as plt # For plotting\n",
    "import seaborn as sns # For nicer plots\n",
    "\n",
    "def analyze_and_plot_clusters(metrics_dict):\n",
    "    \"\"\"\n",
    "    Calculates the Pearson correlation between the *biannual year* (1-2, 3-4, 5-6) \n",
    "    of the student and 'cluster kmeans 3 cat' for each DataFrame.\n",
    "    \n",
    "    Also generates and saves a boxplot visualizing the distribution of \n",
    "    biannual years within each cluster.\n",
    "\n",
    "    Args:\n",
    "        metrics_dict (dict): A dictionary where keys are approach names (str)\n",
    "                             and values are pandas DataFrames.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (dict, list)\n",
    "            - A dictionary of correlation coefficients.\n",
    "            - A list of filenames for the saved plots.\n",
    "    \"\"\"\n",
    "    correlations = {}\n",
    "    plot_files = []\n",
    "    \n",
    "    # Define the column names we need\n",
    "    year_col = 'year'\n",
    "    cluster_col = 'cluster kmeans 3 cat'\n",
    "\n",
    "    for approach_name, df in metrics_dict.items():\n",
    "        print(f\"--- Processing: {approach_name} ---\")\n",
    "        \n",
    "        # Check if the required columns exist in the DataFrame\n",
    "        if year_col in df.columns and cluster_col in df.columns:\n",
    "            try:\n",
    "                # Ensure data is numeric before calculating correlation\n",
    "                year_data = pd.to_numeric(df[year_col], errors='coerce')\n",
    "                cluster_data = pd.to_numeric(df[cluster_col], errors='coerce')\n",
    "                \n",
    "                # Map years to biannual groups (1,2)->1, (3,4)->2, (5,6)->3\n",
    "                biannual_year_data = np.ceil(year_data / 2)\n",
    "                \n",
    "                # Create a clean DataFrame for analysis and plotting\n",
    "                valid_data = pd.DataFrame({\n",
    "                    'biannual_year': biannual_year_data, \n",
    "                    'cluster': cluster_data\n",
    "                }).dropna()\n",
    "                \n",
    "                if not valid_data.empty:\n",
    "                    # 1. Calculate Pearson correlation\n",
    "                    corr = valid_data['biannual_year'].corr(valid_data['cluster'], method='pearson')\n",
    "                    correlations[approach_name] = corr\n",
    "                    print(f\"Biannual Correlation: {corr:.4f}\")\n",
    "                    \n",
    "                    # 2. Generate and save the plot\n",
    "                    plt.figure(figsize=(10, 7))\n",
    "                    # A boxplot shows the distribution (median, quartiles)\n",
    "                    sns.boxplot(\n",
    "                        data=valid_data, \n",
    "                        x='cluster', \n",
    "                        y='biannual_year',\n",
    "                        palette='viridis'\n",
    "                    )\n",
    "                    # A stripplot (jitter) shows the individual data points\n",
    "                    sns.stripplot(\n",
    "                        data=valid_data, \n",
    "                        x='cluster', \n",
    "                        y='biannual_year', \n",
    "                        color='0.3', # dark grey\n",
    "                        alpha=0.4, \n",
    "                        jitter=0.2\n",
    "                    )\n",
    "                    \n",
    "                    plt.title(f'Distribution of Biannual Year by Cluster\\nApproach: {approach_name} (Pearson r: {corr:.3f})', fontsize=16)\n",
    "                    plt.xlabel(cluster_col, fontsize=12)\n",
    "                    plt.ylabel('Biannual Year Group (1-2, 3-4, 5-6)', fontsize=12)\n",
    "                    \n",
    "                    # Save the figure\n",
    "                    plot_filename = f\"{approach_name}_cluster_year_distribution.png\"\n",
    "                    plt.savefig(plot_filename)\n",
    "                    plt.close() # Close the plot to avoid displaying it inline\n",
    "                    \n",
    "                    plot_files.append(plot_filename)\n",
    "                    print(f\"Saved plot to {plot_filename}\")\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"No valid numeric data to correlate after cleaning.\")\n",
    "                    correlations[approach_name] = None\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error during analysis for {approach_name}: {e}\")\n",
    "                correlations[approach_name] = None\n",
    "        else:\n",
    "            print(f\"Skipping {approach_name}: Missing required columns.\")\n",
    "            if year_col not in df.columns:\n",
    "                print(f\"  Missing column: '{year_col}'\")\n",
    "            if cluster_col not in df.columns:\n",
    "                print(f\"  Missing column: '{cluster_col}'\")\n",
    "            correlations[approach_name] = None\n",
    "            \n",
    "    return correlations, plot_files\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # This block will only run when the script is executed directly\n",
    "    \n",
    "    # Define the file paths\n",
    "    file_paths = {\n",
    "        'Human_84': 'medical_specialist/annotations-dpoc-medical_specialist_metrics_84.csv',\n",
    "        'Human_435': 'medical_specialist/aligned_annotations-dpoc-medical_specialist_metrics_435.csv',\n",
    "        'BioBERT': 'biobert_balanced/annotations-dpoc-biobert_metrics.csv',\n",
    "        'BioBERT_Llama': 'biobert-llama_balanced/annotations-dpoc-biobert-llama_metrics.csv',\n",
    "        'Llama': 'llama/annotations-dpoc-llm_10_tf_idf_custom_shot_metrics.csv',\n",
    "    }\n",
    "    \n",
    "    metrics_all = {}\n",
    "    \n",
    "    print(\"Loading CSV files...\")\n",
    "    # Load dataframes, handling potential FileNotFoundError\n",
    "    for name, path in file_paths.items():\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                metrics_all[name] = pd.read_csv(path)\n",
    "                print(f\"Successfully loaded: {path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {path}: {e}\")\n",
    "                metrics_all[name] = pd.DataFrame() # Add empty df to avoid errors later\n",
    "        else:\n",
    "            print(f\"File not found: {path}. Skipping '{name}'.\")\n",
    "            # Create mock data if files don't exist, so the function can be tested\n",
    "            print(f\"Creating mock data for '{name}' for demonstration.\")\n",
    "            \n",
    "            # --- FIXED MOCK DATA to use the new column names ---\n",
    "            metrics_all[name] = pd.DataFrame({\n",
    "                'year': [1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 3, 5],\n",
    "                'cluster kmeans 3 cat': [0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0],\n",
    "                'other_data': ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm']\n",
    "            })\n",
    "\n",
    "    # Check if we have any data to process\n",
    "    if metrics_all:\n",
    "        # Calculate the correlations and generate plots\n",
    "        all_correlations, saved_plots = analyze_and_plot_clusters(metrics_all)\n",
    "        \n",
    "        print(\"\\n--- Final Correlation Results ---\")\n",
    "        for approach, corr_value in all_correlations.items():\n",
    "            if corr_value is not None:\n",
    "                print(f\"{approach}: {corr_value:.4f}\")\n",
    "            else:\n",
    "                print(f\"{approach}: Calculation failed or columns missing\")\n",
    "                \n",
    "        print(\"\\n--- Saved Plot Files ---\")\n",
    "        for plot_file in saved_plots:\n",
    "            print(plot_file)\n",
    "    else:\n",
    "        print(\"\\nNo data was loaded. Please check your file paths.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "\n",
    "# --- User's Data Loading ---\n",
    "# Note: These file paths are from your request.\n",
    "# Please ensure these files are in the correct location relative to this script.\n",
    "try:\n",
    "    metrics_all = {\n",
    "        'Human_84': pd.read_csv('medical_specialist/annotations-dpoc-medical_specialist_metrics_84.csv'),\n",
    "        'Human_435': pd.read_csv('medical_specialist/aligned_annotations-dpoc-medical_specialist_metrics_435.csv'),\n",
    "        'BioBERT': pd.read_csv('biobert_balanced/annotations-dpoc-biobert_metrics.csv'),\n",
    "        'BioBERT_Llama': pd.read_csv('biobert-llama_balanced/annotations-dpoc-biobert-llama_metrics.csv'),\n",
    "        'Llama': pd.read_csv('llama/annotations-dpoc-llm_10_tf_idf_custom_shot_metrics.csv'),\n",
    "        'Llama_aug': pd.read_csv('llama/annotations-dpoc-llm_10_tf_idf_custom_shot_metrics.csv')\n",
    "    }\n",
    "    print(\"Data loaded successfully.\\n\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "    print(\"Please ensure the file paths are correct. Creating dummy data to demonstrate the analysis.\\n\")\n",
    "    # Create dummy data if files aren't found, to show the script works\n",
    "    data = {\n",
    "        'year': np.random.choice([1, 2, 3, 4, 5, 6], 200),\n",
    "        'cluster kmeans 3 cat': np.random.choice(['A', 'B', 'C'], 200)\n",
    "    }\n",
    "    metrics_all = {'Dummy_Data': pd.DataFrame(data)}\n",
    "\n",
    "# --- Analysis ---\n",
    "\n",
    "# Define the columns of interest\n",
    "year_col = \"year\"\n",
    "cluster_col = \"cluster kmeans 3 cat\"\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "# Define the function to map years to biannual groups\n",
    "def group_years(year):\n",
    "    if year in [1, 2]:\n",
    "        return 'Year 1-2'\n",
    "    elif year in [3, 4]:\n",
    "        return 'Year 3-4'\n",
    "    elif year in [5, 6]:\n",
    "        return 'Year 5-6'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Iterate over each DataFrame in the dictionary\n",
    "for model_name, df in metrics_all.items():\n",
    "    print(f\"--- Analyzing: {model_name} ---\")\n",
    "\n",
    "    # Make a copy to avoid SettingWithCopyWarning\n",
    "    df_analysis = df.copy()\n",
    "\n",
    "    # 1. Check if columns exist\n",
    "    if year_col not in df_analysis.columns or cluster_col not in df_analysis.columns:\n",
    "        print(f\"Skipping {model_name}: Missing required columns ('{year_col}' or '{cluster_col}').\\n\")\n",
    "        continue\n",
    "\n",
    "    # 2. Create the biannual year group\n",
    "    df_analysis['biannual_group'] = df_analysis[year_col].apply(group_years)\n",
    "\n",
    "    # 3. Handle missing data\n",
    "    original_count = len(df_analysis)\n",
    "    df_analysis.dropna(subset=['biannual_group', cluster_col], inplace=True)\n",
    "    valid_count = len(df_analysis)\n",
    "    \n",
    "    if valid_count < original_count:\n",
    "        print(f\"Note: Removed {original_count - valid_count} rows with missing data in 'year' or 'cluster' columns.\")\n",
    "    \n",
    "    if valid_count == 0:\n",
    "        print(\"Skipping: No valid data remaining after filtering NaNs.\\n\")\n",
    "        continue\n",
    "\n",
    "    # 4. Create a contingency table (crosstab)\n",
    "    contingency_table = pd.crosstab(df_analysis['biannual_group'], df_analysis[cluster_col])\n",
    "    \n",
    "    print(\"\\nContingency Table (Observed Frequencies):\")\n",
    "    print(contingency_table)\n",
    "\n",
    "    # 5. Perform the Chi-squared test\n",
    "    try:\n",
    "        chi2_stat, p_value, dof, expected_freqs = chi2_contingency(contingency_table)\n",
    "        \n",
    "        print(f\"\\nExpected Frequencies (from Chi-squared test):\")\n",
    "        print(pd.DataFrame(expected_freqs, \n",
    "                           index=contingency_table.index, \n",
    "                           columns=contingency_table.columns).round(2))\n",
    "\n",
    "        # Check assumption: expected frequency > 5\n",
    "        if (expected_freqs < 5).any():\n",
    "            print(\"\\nWarning: Some cells have an expected frequency of less than 5.\")\n",
    "            print(\"The Chi-squared test results may be less reliable.\")\n",
    "\n",
    "        print(f\"\\nChi-squared Test Results:\")\n",
    "        print(f\"  Chi-squared statistic: {chi2_stat:.4f}\")\n",
    "        print(f\"  Degrees of freedom (dof): {dof}\")\n",
    "        print(f\"  p-value: {p_value:.4f}\")\n",
    "\n",
    "        # 6. Interpret the results\n",
    "        if p_value < alpha:\n",
    "            print(f\"\\nInterpretation (p < {alpha}):\")\n",
    "            print(f\"  There IS a statistically significant association between\")\n",
    "            print(f\"  the biannual year group and cluster membership ('{cluster_col}').\")\n",
    "        else:\n",
    "            print(f\"\\nInterpretation (p >= {alpha}):\")\n",
    "            print(f\"  There is NO statistically significant association between\")\n",
    "            print(f\"  the biannual year group and cluster membership ('{cluster_col}').\")\n",
    "    \n",
    "    except ValueError as e:\n",
    "        print(f\"\\nError during Chi-squared test: {e}\")\n",
    "        print(\"This can happen if the contingency table has a row or column with all zeros.\")\n",
    "\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Analysis complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harena_cases_private",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
