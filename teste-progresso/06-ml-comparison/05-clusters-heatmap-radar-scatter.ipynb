{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../annotations')\n",
    "import annotation_metrics as am\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE, Isomap, MDS\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define metrics\n",
    "metrics = ['pathophysiology_norm_mean', 'epidemiology_norm_mean', 'etiology_norm_mean', 'history_norm_mean',\n",
    "           'physical_norm_mean', 'exams_norm_mean', 'differential_norm_mean', 'therapeutic_norm_mean']\n",
    "\n",
    "cluster_methods = [\n",
    "    'kmeans 3 emb', 'kmeans 3 cat',\n",
    "    'agg 3 emb', 'agg 3 cat',\n",
    "    'gmm 3 emb', 'gmm 3 cat',\n",
    "    'birch 3 emb', 'birch 3 cat'\n",
    "]\n",
    "\n",
    "\n",
    "cluster_names = [\"Novice\", \"Developing\", \"Proficient\",\n",
    "                 \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_sets = ['Human_84', 'Human_435', 'BioBERT', 'BioBERT_Llama','Llama', 'Llama_aug']\n",
    "\n",
    "metrics_all = {'Human_84': pd.read_csv('medical_specialist/annotations-dpoc-medical_specialist_metrics_84.csv'),\n",
    "               'Human_435': pd.read_csv('medical_specialist/aligned_annotations-dpoc-medical_specialist_metrics_435.csv'),\n",
    "               'BioBERT': pd.read_csv('biobert_balanced/annotations-dpoc-biobert_metrics.csv'),\n",
    "               'BioBERT_Llama': pd.read_csv('biobert-llama_balanced/annotations-dpoc-biobert-llama_metrics.csv'),\n",
    "               'Llama': pd.read_csv('llama/annotations-dpoc-llm_10_tf_idf_custom_shot_metrics.csv'),\n",
    "            #    'Llama_aug': pd.read_csv('llama/annotations-dpoc-llm_augmented_10_tf_idf_custom_shot_metrics.csv')\n",
    "               'Llama_aug': pd.read_csv('llama/annotations-dpoc-llm_10_tf_idf_custom_shot_metrics.csv')}\n",
    "\n",
    "for metric_label in metrics_all:\n",
    "    metrics_all[metric_label] = metrics_all[metric_label].sort_values('annotation id')\n",
    "\n",
    "common_ids_435 = metrics_all['Human_435']['annotation id'].isin(metrics_all['Llama']['annotation id'])\n",
    "metrics_all['Human_435'] = metrics_all['Human_435'][common_ids_435]\n",
    "metrics_all['Llama'] = metrics_all['Llama'][common_ids_435]\n",
    "metrics_all['Llama_aug'] = metrics_all['Llama_aug'][common_ids_435]\n",
    "\n",
    "common_ids_86 = metrics_all['Human_84']['annotation id'].isin(metrics_all['BioBERT']['annotation id'])\n",
    "metrics_all['Human_84'] = metrics_all['Human_84'][common_ids_86]\n",
    "metrics_all['BioBERT'] = metrics_all['BioBERT'][common_ids_86]\n",
    "metrics_all['BioBERT_Llama'] = metrics_all['BioBERT_Llama'][common_ids_86]\n",
    "\n",
    "stats_all = {'Human_84': pd.read_csv('medical_specialist/annotations-dpoc-medical_specialist_stats_84.csv'),\n",
    "             'Human_435': pd.read_csv('medical_specialist/annotations-dpoc-medical_specialist_stats_435.csv'),\n",
    "             'BioBERT': pd.read_csv('biobert_balanced/annotations-dpoc-biobert_stats.csv'),\n",
    "             'BioBERT_Llama': pd.read_csv('biobert-llama_balanced/annotations-dpoc-biobert-llama_stats.csv'),\n",
    "             'Llama': pd.read_csv('llama/annotations-dpoc-llm_10_tf_idf_custom_shot_stats.csv'),\n",
    "            #  'Llama_aug': pd.read_csv('llama/annotations-dpoc-llm_augmented_10_tf_idf_custom_shot_stats.csv')\n",
    "             'Llama_aug': pd.read_csv('llama/annotations-dpoc-llm_10_tf_idf_custom_shot_stats.csv')}\n",
    "\n",
    "reduction_method = ['tsne', 'pca', 'isomap', 'mds']\n",
    "reduction_all = {}\n",
    "for ann_set in annotation_sets:\n",
    "    tsne = TSNE(n_components=2, random_state=42, init='pca')\n",
    "    pca = PCA(n_components=2)\n",
    "    isomap = Isomap(n_components=2)\n",
    "    mds = MDS(n_components=2, random_state=42)\n",
    "    reduction_all[ann_set] = {\n",
    "        'tsne': tsne.fit_transform(metrics_all[ann_set][am.cluster_labels].values),\n",
    "        'pca': pca.fit_transform(metrics_all[ann_set][am.cluster_labels].values),\n",
    "        'isomap': isomap.fit_transform(metrics_all[ann_set][am.cluster_labels].values),\n",
    "        'mds': mds.fit_transform(metrics_all[ann_set][am.cluster_labels].values)\n",
    "    }\n",
    "\n",
    "comparison = [['Human_435', 'Llama'], ['Human_84', 'BioBERT'], ['Human_84', 'BioBERT_Llama'], ['Llama', 'Llama_aug'], ['Human_435', 'Llama_aug']]\n",
    "\n",
    "def create_radar_charts(method_data, method, stats_label):\n",
    "    \"\"\"Create radar charts from DataFrame\"\"\"\n",
    "    metrics = ['pathophysiology_norm_mean', 'epidemiology_norm_mean', 'etiology_norm_mean', 'history_norm_mean',\n",
    "               'physical_norm_mean', 'exams_norm_mean', 'differential_norm_mean', 'therapeutic_norm_mean']\n",
    "    \n",
    "    clusters = method_data['cluster'].unique()\n",
    "    \n",
    "    # Calculate subplot layout\n",
    "    n_clusters = len(clusters)\n",
    "    n_rows = (n_clusters + 2) // 3  # Max 3 plots per row\n",
    "    n_cols = min(n_clusters, 3)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axs = plt.subplots(\n",
    "        n_rows, n_cols, \n",
    "        figsize=(5*n_cols, 5*n_rows), \n",
    "        subplot_kw={'projection': 'polar'}\n",
    "    )\n",
    "    \n",
    "    # Flatten axs for easier indexing if multiple rows\n",
    "    if n_clusters > 1:\n",
    "        axs = axs.flatten() if n_rows > 1 else axs\n",
    "    \n",
    "    # Color map for different clusters\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(clusters)))\n",
    "    \n",
    "    # Plot data for each cluster\n",
    "    for i, (cluster, color) in enumerate(zip(clusters, colors)):\n",
    "        # Handle subplot indexing\n",
    "        ax = axs[i] if n_clusters > 1 else axs\n",
    "        \n",
    "        cluster_data = method_data[method_data['cluster'] == cluster]\n",
    "        values = cluster_data[metrics].values.flatten()\n",
    "        \n",
    "        # Compute angles for metrics\n",
    "        theta = np.linspace(0, 2*np.pi, len(metrics), endpoint=False)\n",
    "        \n",
    "        # Close the plot by repeating the first value\n",
    "        values = np.concatenate((values, [values[0]]))\n",
    "        theta = np.concatenate((theta, [theta[0]]))\n",
    "        \n",
    "        # Plot the radar chart\n",
    "        ax.plot(theta, values, color=color)\n",
    "        ax.fill(theta, values, color=color, alpha=0.25)\n",
    "        \n",
    "        # Set labels\n",
    "        ax.set_xticks(theta[:-1])\n",
    "        ax.set_xticklabels([\n",
    "            metric.replace('_norm_mean', '').replace('_', ' ').title() \n",
    "            for metric in metrics\n",
    "        ])\n",
    "        \n",
    "        # Set title with cluster and year\n",
    "        ots_min = cluster_data['objective test score_min'].values[0]\n",
    "        ots_max = cluster_data['objective test score_max'].values[0]\n",
    "        ots_mean = cluster_data['objective test score_mean'].values[0]\n",
    "        ol_min = cluster_data['organization level_min'].values[0]\n",
    "        ol_max = cluster_data['organization level_max'].values[0]\n",
    "        ol_mean = cluster_data['organization level_mean'].values[0]\n",
    "        gs_min = cluster_data['global score_min'].values[0]\n",
    "        gs_max = cluster_data['global score_max'].values[0]\n",
    "        gs_mean = cluster_data['global score_mean'].values[0]\n",
    "\n",
    "        ax.set_title(f'Cluster {cluster_names[cluster]}\\nobjective test {ots_min}-{ots_max} / {ots_mean:.1f} avg\\n' +\n",
    "                     f'organization level {ol_min}-{ol_max} / {ol_mean:.1f} avg\\n' +\n",
    "                     f'global score {gs_min}-{gs_max} / {gs_mean:.1f} avg')\n",
    "    \n",
    "    # Remove extra subplots if any\n",
    "    if n_clusters < len(axs.flatten()):\n",
    "        for j in range(n_clusters, len(axs.flatten())):\n",
    "            fig.delaxes(axs.flatten()[j])\n",
    "    \n",
    "    # Overall figure title\n",
    "    fig.suptitle(f'{method} - {stats_label}', fontsize=16)\n",
    "    \n",
    "    # Adjust layout and display\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for comparison_pair in comparison:\n",
    "    for method in cluster_methods:\n",
    "        # Heatmap\n",
    "        # -------\n",
    "\n",
    "        column_name = f'cluster {method}'\n",
    "\n",
    "        cluster1_labels = metrics_all[comparison_pair[0]][column_name].values\n",
    "        cluster2_labels = metrics_all[comparison_pair[1]][column_name].values\n",
    "\n",
    "        # Create contingency matrix\n",
    "        contingency = confusion_matrix(cluster1_labels, cluster2_labels)\n",
    "\n",
    "        # Calculate proportion matrix\n",
    "        row_sums = contingency.sum(axis=1).reshape(-1, 1)\n",
    "        proportion_matrix = contingency / row_sums\n",
    "\n",
    "        # Plot contingency matrix heatmap\n",
    "        plt.subplot(212)\n",
    "        sns.heatmap(proportion_matrix, annot=True, fmt='.2f', cmap='YlOrRd',\n",
    "                    xticklabels=[f'{comparison_pair[1]} {cluster_names[i]}' for i in range(len(np.unique(cluster2_labels)))],\n",
    "                    yticklabels=[f'{comparison_pair[0]} {cluster_names[i]}' for i in range(len(np.unique(cluster1_labels)))],\n",
    "                    vmin=0, vmax=1)\n",
    "        plt.title(f'{comparison_pair[0]} vs {comparison_pair[1]} - Proportion Matrix for {method}')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Radar Plot\n",
    "        # ----------\n",
    "\n",
    "        for stats_label in comparison_pair:\n",
    "            stats = stats_all[stats_label]\n",
    "            method_data = stats[stats['method'] == method]\n",
    "            create_radar_charts(method_data, method, stats_label)\n",
    "\n",
    "            # Bar Chart\n",
    "            # ---------\n",
    "\n",
    "            # Extract year columns\n",
    "            year_columns = ['year_1', 'year_2', 'year_3', 'year_4', 'year_5', 'year_6']\n",
    "\n",
    "            # Plot bar chart for each cluster\n",
    "            clusters = method_data['cluster'].unique()\n",
    "            n_clusters = len(clusters)\n",
    "            \n",
    "            fig, axs = plt.subplots(1, n_clusters, figsize=(5 * n_clusters, 6), sharey=True)\n",
    "            \n",
    "            if n_clusters == 1:\n",
    "                axs = [axs]\n",
    "            \n",
    "            for ax, cluster in zip(axs, clusters):\n",
    "                cluster_data = method_data[method_data['cluster'] == cluster]\n",
    "                ax.bar(year_columns, cluster_data[year_columns].values.flatten(), label=f'Cluster {cluster}')\n",
    "                ax.set_title(f'Cluster {cluster_names[cluster]}')\n",
    "                ax.set_xlabel('Students per Year')\n",
    "                ax.set_ylabel('Values')\n",
    "                ax.legend()\n",
    "\n",
    "            # Display the bar chart\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Scatter Plot\n",
    "        # ------------\n",
    "\n",
    "        fig, axs = plt.subplots(4, 4, figsize=(20, 16))\n",
    "        axs = axs.flatten()\n",
    "\n",
    "        pos = 0\n",
    "\n",
    "        combination = [[0, 0], [1,1], [0,1], [1,0]]\n",
    "        for comb in combination:\n",
    "            for rm in reduction_method:\n",
    "                scatter = axs[pos].scatter(\n",
    "                    reduction_all[comparison_pair[comb[1]]][rm][:, 0],\n",
    "                    reduction_all[comparison_pair[comb[1]]][rm][:, 1],\n",
    "                    c=metrics_all[comparison_pair[comb[0]]][column_name].values, cmap='viridis', alpha=0.6)\n",
    "                fig.colorbar(scatter, ax=axs[pos], label='Cluster')\n",
    "                axs[pos].set_title(\n",
    "                    f'{comparison_pair[comb[0]]} ann/{comparison_pair[comb[1]]} spc-{method}')\n",
    "                axs[pos].set_xlabel(f'{rm} 1')\n",
    "                axs[pos].set_ylabel(f'{rm} 2')\n",
    "                pos += 1\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
