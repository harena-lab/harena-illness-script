{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def get_random_pieces(file_path, num_pieces):\n",
    "    random_pieces = []\n",
    "    csv_data = pd.read_csv(file_path)\n",
    "    for index, row in csv_data.iterrows():\n",
    "        random_pieces.append([row['text'],row['cluster_labels']])\n",
    "    \n",
    "    random.shuffle(random_pieces)\n",
    "    return random_pieces[:num_pieces]\n",
    "\n",
    "file_path = \"annotations_medical_specialist_pre_processed_no_short.csv\"\n",
    "num_pieces = 5\n",
    "\n",
    "random_pieces = get_random_pieces(file_path, num_pieces)\n",
    "print(random_pieces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import random\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "def get_all_data(file_path):\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        data = [line for line in reader]\n",
    "    return data\n",
    "\n",
    "def get_random_pieces(file_path, num_pieces):\n",
    "    random_pieces = []\n",
    "    \n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        for line in reader:\n",
    "            if len(line['cluster_labels']) > 0:\n",
    "                line.pop('doc_id', None)\n",
    "                for annotation in line['cluster_labels']:\n",
    "                    annotation[1:-1] = []\n",
    "                random_pieces.append(line)\n",
    "    \n",
    "    random.shuffle(random_pieces)\n",
    "    return random_pieces[:num_pieces]\n",
    "\n",
    "def count_annotations(file_path, num_objects):\n",
    "    \n",
    "    \n",
    "    top_objects = []\n",
    "\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        for line in reader:\n",
    "            category_count = {\n",
    "                'pathophysiology': 0, \n",
    "                'etiology': 0, \n",
    "                'epidemiology': 0, \n",
    "                'history': 0, \n",
    "                'physical': 0, \n",
    "                'exams': 0, \n",
    "                'differential': 0, \n",
    "                'therapeutic': 0\n",
    "                }\n",
    "            if len(line['cluster_labels']) > 0:\n",
    "                for annotation in line['cluster_labels']:\n",
    "                    annotation[1:-1] = []\n",
    "                \n",
    "                for annotation in line['cluster_labels']:\n",
    "                    for item in annotation[1]:\n",
    "                        if item in category_count.keys():\n",
    "                            category_count[item] += 1\n",
    "                count = sum(category_count[item] for item in annotation[1] if item in category_count.keys())\n",
    "                categories_utilized = sum(1 for value in category_count.values() if value != 0)\n",
    "                line['diversity'] = (categories_utilized/len(category_count))*count\n",
    "                top_objects.append(line)\n",
    "\n",
    "    category_count = {\n",
    "        'pathophysiology': 0, \n",
    "        'etiology': 0, \n",
    "        'epidemiology': 0, \n",
    "        'history': 0, \n",
    "        'physical': 0, \n",
    "        'exams': 0, \n",
    "        'differential': 0, \n",
    "        'therapeutic': 0\n",
    "        }\n",
    "    \n",
    "    top_objects.sort(key=lambda x: (x.get('diversity', 0)), reverse=True)\n",
    "    top_objects = top_objects[:num_objects]\n",
    "    \n",
    "    return top_objects\n",
    "\n",
    "def count_annotations_cluster(annotation_list,num_objects):\n",
    "    top_objects = []\n",
    "    for line in annotation_list.iterrows():\n",
    "        category_count = {\n",
    "            'pathophysiology': 0, \n",
    "            'etiology': 0, \n",
    "            'epidemiology': 0, \n",
    "            'history': 0, \n",
    "            'physical': 0, \n",
    "            'exams': 0, \n",
    "            'differential': 0, \n",
    "            'therapeutic': 0\n",
    "            }\n",
    "\n",
    "        for item_ann in line:\n",
    "            if isinstance(item_ann, pd.Series):\n",
    "                item_ann_dict = item_ann.to_dict()\n",
    "                item_ann_dict['doc_id'] = line[0] if len(line) == 2 else None\n",
    "            # annotation[1:-1] = []\n",
    "\n",
    "        for annotation in ast.literal_eval(item_ann_dict['cluster_labels']):\n",
    "            for item in annotation[1]:\n",
    "                if item in category_count.keys():\n",
    "                    category_count[item] += 1\n",
    "        count = sum(category_count[item] for item in annotation[1] if item in category_count.keys())\n",
    "        categories_utilized = sum(1 for value in category_count.values() if value != 0)\n",
    "        item_ann_dict['diversity'] = (categories_utilized/len(category_count))*count\n",
    "        # print(item_ann_dict['doc_id'] )\n",
    "        # print(item_ann_dict['diversity'] )\n",
    "        top_objects.append(item_ann_dict)\n",
    "    top_objects.sort(key=lambda x: (x.get('diversity', 0)), reverse=True)\n",
    "    category_count = {\n",
    "            'pathophysiology': 0, \n",
    "            'etiology': 0, \n",
    "            'epidemiology': 0, \n",
    "            'history': 0, \n",
    "            'physical': 0, \n",
    "            'exams': 0, \n",
    "            'differential': 0, \n",
    "            'therapeutic': 0\n",
    "            }\n",
    "    return top_objects[:num_objects]\n",
    "def get_top_objects(file_path, num_objects):\n",
    "    objects = []\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        for line in reader:\n",
    "            if len(line['labels']) > 0:\n",
    "                for annotation in line['labels']:\n",
    "                    annotation[1:-1] = []\n",
    "                objects.append(line)\n",
    "    \n",
    "            \n",
    "\n",
    "    objects.sort(key=lambda x: x.get('annotation', 0), reverse=True)\n",
    "    top_objects = objects[:num_objects]\n",
    "    \n",
    "    return top_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "file_path = \"annotations_medical_specialist_pre_processed_no_short.csv\"\n",
    "num_objects = 11\n",
    "df_annotations = pd.read_csv(file_path)\n",
    "df_annotations.set_index('doc_id', inplace=True)\n",
    "# print(df_annotations['cluster_labels'])\n",
    "\n",
    "top_objects = count_annotations_cluster(df_annotations, num_objects)\n",
    "\n",
    "# category_translation = {'pathophysiology': 'fisiopatologia', \n",
    "#                         'etiology': 'etiologia', \n",
    "#                         'epidemiology': 'epidemiologia', \n",
    "#                         'history': 'história', \n",
    "#                         'physical': 'exame físico', \n",
    "#                         'exams': 'exames complementares', \n",
    "#                         'differential': 'diagnóstico diferencial', \n",
    "#                         'therapeutic': 'tratamento',\n",
    "#                         'simple':'simples',\n",
    "#                         'wrong':'errado',\n",
    "#                         'right':'certo',\n",
    "#                         'jargon':'jargão',\n",
    "#                         'encapsulated':'encapsulado'\n",
    "#                         }\n",
    "\n",
    "category_minimization = {'pathophysiology': 1, \n",
    "                        'etiology': 2, \n",
    "                        'epidemiology': 3, \n",
    "                        'history': 4, \n",
    "                        'physical': 5, \n",
    "                        'exams': 6, \n",
    "                        'differential': 7, \n",
    "                        'therapeutic': 8,\n",
    "                        }\n",
    "translated_top_objects = top_objects\n",
    "\n",
    "for obj in translated_top_objects:\n",
    "    category_count = {\n",
    "        'pathophysiology': 0, \n",
    "        'etiology': 0, \n",
    "        'epidemiology': 0, \n",
    "        'history': 0, \n",
    "        'physical': 0, \n",
    "        'exams': 0, \n",
    "        'differential': 0, \n",
    "        'therapeutic': 0,\n",
    "    }\n",
    "    annotations = obj.get('cluster_labels', [])\n",
    "    annotations = ast.literal_eval(annotations)\n",
    "    for i in range(len(annotations)):\n",
    "        # print(annotations[i])\n",
    "        replacements = []\n",
    "        for item in annotations[i][1]:\n",
    "            if item in category_count.keys():\n",
    "                category_count[item] += 1\n",
    "        #         replacements.append(category_minimization[category_count[item]])\n",
    "        #     else:\n",
    "        #         replacements.append(item)\n",
    "        \n",
    "        # annotations[i][1] = replacements\n",
    "    # print(category_count)\n",
    "    obj['cluster_labels'] = annotations\n",
    "# print(translated_top_objects)\n",
    "\n",
    "# Convert top_objects to JSON lines format\n",
    "json_lines = [json.dumps(obj,ensure_ascii=False) for obj in translated_top_objects]\n",
    "json_lines_str = '\\n'.join(json_lines)\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "with jsonlines.open(f'prompt-shots-{now.day}-{now.month}.jsonl', 'w') as writer:\n",
    "    writer.write_all(translated_top_objects)\n",
    "# print(translated_top_objects)\n",
    "# print(decoded_json_lines_str)\n",
    "# print(translated_top_objects)\n",
    "# print(str({'text':json.loads(json_lines[0])['text']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_organization_lvl = {'less':[],'semi':[],'super':[],'one':[],'two':[],'three':[],'four':[],'five':[],'six':[],'seven':[],'eight':[],'nine':[],'ten':[]}\n",
    "prompt_global_score = {'less':[],'semi':[],'super':[],'one':[],'two':[],'three':[],'four':[],'five':[],'six':[],'seven':[],'eight':[],'nine':[],'ten':[]}\n",
    "prompt_ideas = {'less':[],'semi':[],'super':[],'one':[],'two':[],'three':[],'four':[],'five':[],'six':[],'seven':[],'eight':[],'nine':[],'ten':[]}\n",
    "prompt_ideas_full = {'less':['Preciso que você avalie o seguinte texto de um aluno de medicina. Calcule a quantidade de ideias escritas no texto. Após calcular a quantidade, retorne as partes do texto consideradas como ideias. Para responder, siga o formato em JSON a seguir:\\n<<{‘text’:{texto avaliado},’annotations’:{[[‘ideia1’],[‘ideia2’],[‘ideiaN’]]}}>>\\nA pergunta sobre o assunto está a seguir, começando após \"P.\". A resposta à pergunta começa logo após \"R.\".\\nP. Fale TUDO que você sabe sobre infarto agudo do miocárdio. TODAS as informações que você souber são importantes.\\nR.'],\n",
    "                     'semi':['Preciso que você avalie o seguinte texto de um aluno de medicina. O texto pode ser dividido em unidades de ideias. Essas unidades de ideias podem ser referente a uma ou mais das categorias a seguir: fisiopatologia, epidemiologia, etiologia, história, exame físico, exames complementares, diagnóstico diferencial, tratamento.\\nApós dividir o texto em unidades de ideias, retorne as partes do texto consideradas como ideias no formato a seguir:\\n<<{‘text’:”texto avaliado”,’annotations’:[[‘ideia1’,[‘categoria1’,’categoriaN’]],[‘ideia2’,[‘categoria1’,’categoriaN’]],[‘ideiaN’,[‘categoria1’,’categoriaN’]]]}>>\\nA pergunta sobre o assunto está a seguir, começando após \"P.\". A resposta à pergunta começa logo após \"R.\".\\nP. Fale TUDO que você sabe sobre infarto agudo do miocárdio. TODAS as informações que você souber são importantes.\\nR.'],\n",
    "                     'super':[],\n",
    "                     'one-few':['Preciso que você avalie o seguinte texto de um aluno de medicina. O texto pode ser dividido em unidades de ideias. Essas unidades podem ser referente a fisiopatologia, epidemiologia, etiologia, história, exame físico, exames complementares, diagnóstico diferencial, tratamento (algumas ideias pertencem a mais de uma dessas categorias).\\nSepare e classifique as ideias no texto.\\nA pergunta sobre o assunto está a seguir, começando após \"P.\". A resposta à pergunta começa logo após \"R.\".\\n{{example}}\\n'],\n",
    "                     }\n",
    "\n",
    "\n",
    "# str({'text':json.loads(json_lines[i])['text']})\n",
    "# str({'annotations':json.loads(json_lines[i])['annotations']})\n",
    "\n",
    " #json_lines[i]\n",
    "\n",
    "example = count_annotations(file_path, 10)\n",
    "llama_config = {\"top_p\": 0.6,\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_k\": 50,\n",
    "    \"max_new_tokens\": 4096,\n",
    "    \"repetition_penalty\": 1.03\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for Llama predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "def format_messages(messages: List[Dict[str, str]]) -> List[str]:\n",
    "    \"\"\"Format messages for Llama-2 chat models.\n",
    "    \n",
    "    The model only supports 'system', 'user' and 'assistant' roles, starting with 'system', then 'user' and \n",
    "    alternating (u/a/u/a/u...). The last message must be from 'user'.\n",
    "    \"\"\"\n",
    "    prompt: List[str] = []\n",
    "\n",
    "    if messages[0][\"role\"] == \"system\":\n",
    "        content = \"\".join([\"<<SYS>>\\n\", messages[0][\"content\"], \"\\n<</SYS>>\\n\\n\", messages[1][\"content\"]])\n",
    "        messages = [{\"role\": messages[1][\"role\"], \"content\": content}] + messages[2:]\n",
    "\n",
    "    for user, answer in zip(messages[::2], messages[1::2]):\n",
    "        prompt.extend([\"<s>\", \"[INST] \", (user[\"content\"]).strip(), \" [/INST] \", (answer[\"content\"]).strip(), \"</s>\"])\n",
    "\n",
    "    prompt.extend([\"<s>\", \"[INST] \", (messages[-1][\"content\"]).strip(), \" [/INST] \"])\n",
    "\n",
    "    return \"\".join(prompt)\n",
    "\n",
    "def get_text_example(text):\n",
    "    return str({\"text\":text})\n",
    "\n",
    "def set_prompt(prompt_type, prompt_guide_level, prompt_pos, prompt_shot_amount):\n",
    "  # user_prompt = prompt_type[prompt_guide_level][prompt_pos]\n",
    "\n",
    "  ideas_shot_template = \"P. Fale TUDO que você sabe sobre doença pulmonar obstrutiva crônica. TODAS as informações que você souber são importantes.\\nR.<<{{studentResponse}}>>\\nSeparação e classificação de ideias:\\n<<{{annotationsResponse}}>>\"\n",
    "  system_prompt = \"Você é um médico especialista com conhecimento médico e clínico sobre medicina interna, principalmente sobre as doenças doença pulmonar obstrutiva crônica (DPOC) e infarto agudo do miocárdio (IAM). Além disso, você consegue diferenciar entre textos de especialistas sobre IAM e DPOC e textos de alunos. Seu objetivo é avaliar textos de alunos de medicina. Não crie informações que não sejam verdadeiras. Responda no formato mostrado pelo usuário.\"\n",
    "  \n",
    "  if prompt_guide_level == 'one-few':\n",
    "    example_shots = ''\n",
    "    for i in range(prompt_shot_amount):\n",
    "      example_shots.join(ideas_shot_template.replace('{{studentResponse}}', get_text_example(example[i]['text'])).replace('{{annotationsResponse}}', example[i]))\n",
    "      user_prompt = prompt_type[prompt_guide_level][prompt_pos].replace('{{example}}', example_shots)\n",
    "      user_prompt = user_prompt.replace('\\\\n', '\\n')\n",
    "  else:\n",
    "    example_shots = ideas_shot_template.replace('{{studentResponse}}', get_text_example(example[0]['text'])).replace('Separação e classificação de ideias:\\n<<{{annotationsResponse}}>>', '')\n",
    "    user_prompt = prompt_type[prompt_guide_level][prompt_pos].replace('{{example}}', example_shots)\n",
    "    user_prompt = user_prompt.replace('\\\\n', '\\n')\n",
    "\n",
    "  dialog = [\n",
    "    { \"role\": \"system\",\"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]\n",
    "  input = format_messages(dialog)\n",
    "  return input\n",
    "\n",
    "  \n",
    "def prompt_routine(input, num_replicas, top_p,temp,top_k):\n",
    "    prompt_list = []\n",
    "    llama_config[\"top_p\"] = top_p\n",
    "    llama_config[\"temperature\"] = temp \n",
    "    llama_config[\"top_k\"] = top_k\n",
    "    payload = {\n",
    "    \"inputs\":  input,\n",
    "      \"parameters\": {\n",
    "        \"do_sample\": True,\n",
    "        \"top_p\": llama_config[\"top_p\"],\n",
    "        \"temperature\": llama_config[\"temperature\"],\n",
    "        \"top_k\": llama_config[\"top_k\"]\n",
    "      }\n",
    "    }\n",
    "    for i in range(num_replicas):\n",
    "        predictior_output = predictor.predict(payload)\n",
    "        prompt_list.append(predictior_output[0][\"generated_text\"][len(input):])\n",
    "    return prompt_list\n",
    "\n",
    "# input = format_messages(dialog)\n",
    "\n",
    "# payload = {\n",
    "#   \"inputs\":  input,\n",
    "#   \"parameters\": {\n",
    "#     \"do_sample\": True,\n",
    "#     \"top_p\": llama_config[\"top_p\"],\n",
    "#     \"temperature\": llama_config[\"temperature\"],\n",
    "#     \"top_k\": llama_config[\"top_k\"],\n",
    "#     # \"repetition_penalty\": llama_config[\"repetition_penalty\"],\n",
    "#     # \"stop\": [\"</s>\"]\n",
    "#   }\n",
    "# }\n",
    "\n",
    "# send request to endpoint\n",
    "# response = predictor.predict(payload)\n",
    "\n",
    "# print(response[0][\"generated_text\"][len(input):])\n",
    "# chat = predictor.predict({\"inputs\":prompt})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "test_str = '{\\n\"annotations\": [\\n\"ideia1\": [\"limitação do fluxo de ar na árvore respiratória\"],\\n\"ideia2\": [\"resposta inflamatória crônica a agressões ambientais\"],\\n\"ideia3\": [\"diagnóstico por meio de anamnese, exame físico e espirometria\"],\\n\"ideia4\": [\"tratamento com broncodilatadores, corticosteroides, oxigenoterapia e antibióticos\"]\\n]\\n}'\n",
    "# Extract the values of ideias for each answer using regular expressions\n",
    "ideas = re.findall(r'\"ideia\\d+\": \\[\"(.*?)\"\\]', test_str)\n",
    "dict_ideas = {}\n",
    "# Print the array of ideias\n",
    "# print(ideas)\n",
    "\n",
    "with open(\"test.txt\", \"r\") as file:\n",
    "    content = file.read()\n",
    "    array = [line.replace('\\n', '') for line in content.splitlines()]\n",
    "    \n",
    "    blocks = []\n",
    "    for line in array:\n",
    "        line = line.replace('\\n', '')\n",
    "        match = re.search(r'{(.*?)}', line)\n",
    "        if match:\n",
    "            block = match.group(0)\n",
    "            blocks.append(block)\n",
    "            # print(block)\n",
    "i = 0\n",
    "for block in blocks:\n",
    "    block = block.replace('\\n','')\n",
    "    idea = re.findall(r'\"ideia\\d+\": \\[\"(.*?)\"\\]', block)\n",
    "    dict_ideas[i] = idea\n",
    "    i += 1\n",
    "# splited_answers = blocks[0].split('],')\n",
    "printed_lengths = set()\n",
    "length_count = {}\n",
    "\n",
    "for obj in dict_ideas.values():\n",
    "    length = len(obj)\n",
    "    if length not in printed_lengths:\n",
    "        # print(length)\n",
    "        printed_lengths.add(length)\n",
    "    length_count[length] = length_count.get(length, 0) + 1\n",
    "\n",
    "print(\"Amount of objects with each length:\")\n",
    "for length, count in length_count.items():\n",
    "    print(f\"Length {length}: {count} objects\")\n",
    "top_length = max(length_count, key=lambda x: x)\n",
    "print(\"Biggest length:\", top_length)\n",
    "\n",
    "\n",
    "# Print the most used values throughout all objects in descending order\n",
    "value_count = {}\n",
    "for obj in dict_ideas.values():\n",
    "    for value in obj:\n",
    "        value_count[value] = value_count.get(value, 0) + 1\n",
    "sorted_values = sorted(value_count.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Most used values:\")\n",
    "topN = sorted_values[:top_length]\n",
    "for value, count in topN:\n",
    "    print(f\"{value}: {count} times\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"r\") as file:\n",
    "    content = file.read()\n",
    "    array = [line.replace('\\n', '') for line in content.splitlines()]\n",
    "print(array[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    \"name\": \"John\",\n",
    "    \"age\": 30,\n",
    "    \"city\": \"New York\"\n",
    "}\n",
    "\n",
    "file_path = \"data.json\"\n",
    "\n",
    "with open(file_path, \"w\") as file:\n",
    "    json.dump(data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_batch = get_all_data(file_path)\n",
    "prompt_category = 'ideas'\n",
    "guided_lvl = 'less'\n",
    "\n",
    "report_path = f'llama-outputs/temp-{str(llama_config[\"temperature\"])}/top-p-{str(llama_config[\"top_p\"])}'\n",
    "if not os.path.exists(report_path):\n",
    "    os.makedirs(report_path)\n",
    "with jsonlines.open(f'{report_path}/{prompt_category}-{guided_lvl}.jsonl', 'w') as writer:\n",
    "    writer.write_all(output_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_item = random.choice(output_batch)\n",
    "print(random_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
