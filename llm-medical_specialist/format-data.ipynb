{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "def get_examples(file_path):\n",
    "    jsonl_data = []\n",
    "    with open(file_path, 'r',encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            jsonl_data.append(json.loads(line))\n",
    "    return jsonl_data\n",
    "    # with jsonlines.open(file_path) as reader:\n",
    "    #     data = [line for line in reader]\n",
    "    # return data\n",
    "\n",
    "annotated_dataset = get_examples('../teste-progresso/04-ml/annotations-medical_specialist-dpoc-bio-composed-multiple.jsonl')\n",
    "\n",
    "# model_response = [\"{\\n'annotations': [\\n['fibrose', ['pathophysiology']],\\n['perda de elasticidade pulmonar', ['pathophysiology']],\\n['dificultando a eliminação de ar na fase expiratória', ['pathophysiology']],\\n['altas cargas tabágicas', ['epidemiology', 'etiology']],\\n['espirometria', ['exams']],\\n['redução da razão: volume espiratório forçado em 1 segundo pela capacidade pulmonar', ['exams']],\\n['Sem melhora após uso de broncodilatadores', ['history']],\\n['clínica pode ser exarcerbada diante de quadros infecciosos', ['history', 'pathophysiology']],\\n['descompensação de demais comorbidades', ['history', 'pathophysiology']],\\n['medidas de suporte com o2 domiciliar', ['therapeutic']]\\n]\\n}\"]\n",
    "# full_text = \"A DPOC é uma patologia caracterizada pela fibrose e perda de elasticidade pulmonar dificultando a eliminação de ar na fase expiratória. Seu desenvolvimento está, na grande maioria das vezes ligado a altas cargas tabágicas. Seu diagnóstico pode ser dado pela espirometria, com redução da razão: volume espiratório forçado em 1 segundo pela capacidade pulmonar. Sem melhora após uso de broncodilatadores. Sua clínica pode ser exarcerbada diante de quadros infecciosos ou descompensação de demais comorbidades e seu tratamento envolve medidas de suporte com o2 domiciliar (se necessário)\"\n",
    "text_tokenized = {\"labels\":[[\"A\",0,0,\"O\",None],[\"DPOC\",2,5,\"O\",None],[\"é\",7,7,\"O\",None],[\"uma\",9,11,\"O\",None],[\"patologia\",13,21,\"O\",None],[\"caracterizada\",23,35,\"O\",None],[\"pela\",37,40,\"O\",None],[\"fibrose\",42,48,\"B\",{\"pathophysiology\":[9]}],[\"e\",50,50,\"O\",None],[\"perda\",52,56,\"B\",{\"pathophysiology\":[10]}],[\"de\",58,59,\"I\",{\"pathophysiology\":[10]}],[\"elasticidade\",61,72,\"I\",{\"pathophysiology\":[10]}],[\"pulmonar\",74,81,\"I\",{\"pathophysiology\":[10]}],[\"dificultando\",83,94,\"B\",{\"pathophysiology\":[11]}],[\"a\",96,96,\"I\",{\"pathophysiology\":[11]}],[\"eliminação\",98,107,\"I\",{\"pathophysiology\":[11]}],[\"de\",109,110,\"I\",{\"pathophysiology\":[11]}],[\"ar\",112,113,\"I\",{\"pathophysiology\":[11]}],[\"na\",115,116,\"I\",{\"pathophysiology\":[11]}],[\"fase\",118,121,\"I\",{\"pathophysiology\":[11]}],[\"expiratória\",123,133,\"I\",{\"pathophysiology\":[11]}],[\".\",134,134,\"O\",None],[\"Seu\",136,138,\"O\",None],[\"desenvolvimento\",140,154,\"O\",None],[\"está\",156,159,\"O\",None],[\",\",160,160,\"O\",None],[\"na\",162,163,\"O\",None],[\"grande\",165,170,\"O\",None],[\"maioria\",172,178,\"O\",None],[\"das\",180,182,\"O\",None],[\"vezes\",184,188,\"O\",None],[\"ligado\",190,195,\"O\",None],[\"a\",197,197,\"O\",None],[\"altas\",199,203,\"B\",{\"epidemiology\":[1]}],[\"cargas\",205,210,\"I\",{\"epidemiology\":[1]}],[\"tabágicas\",212,220,\"I\",{\"epidemiology\":[1]}],[\".\",221,221,\"O\",None],[\"Seu\",223,225,\"O\",None],[\"diagnóstico\",227,237,\"O\",None],[\"pode\",239,242,\"O\",None],[\"ser\",244,246,\"O\",None],[\"dado\",248,251,\"O\",None],[\"pela\",253,256,\"O\",None],[\"espirometria\",258,269,\"B\",{\"exams\":[3,4,5]}],[\",\",270,270,\"O\",None],[\"com\",272,274,\"O\",None],[\"redução\",276,282,\"B\",{\"exams\":[4,5]}],[\"da\",284,285,\"I\",{\"exams\":[4,5]}],[\"razão\",287,291,\"I\",{\"exams\":[4,5]}],[\":\",292,292,\"I\",{\"exams\":[4,5]}],[\"volume\",294,299,\"I\",{\"exams\":[4,5]}],[\"espiratório\",301,311,\"I\",{\"exams\":[4,5]}],[\"forçado\",313,319,\"I\",{\"exams\":[4,5]}],[\"em\",321,322,\"I\",{\"exams\":[4,5]}],[\"1\",324,324,\"I\",{\"exams\":[4,5]}],[\"segundo\",326,332,\"I\",{\"exams\":[4,5]}],[\"pela\",334,337,\"I\",{\"exams\":[4,5]}],[\"capacidade\",339,348,\"I\",{\"exams\":[4,5]}],[\"pulmonar\",350,357,\"I\",{\"exams\":[4,5]}],[\".\",358,358,\"O\",None],[\"Sem\",360,362,\"B\",{\"exams\":[5]}],[\"melhora\",364,370,\"I\",{\"exams\":[5]}],[\"após\",372,375,\"I\",{\"exams\":[5]}],[\"uso\",377,379,\"I\",{\"exams\":[5]}],[\"de\",381,382,\"I\",{\"exams\":[5]}],[\"broncodilatadores\",384,400,\"I\",{\"exams\":[5]}],[\".\",401,401,\"O\",None],[\"Sua\",403,405,\"O\",None],[\"clínica\",407,413,\"B\",{\"history\":[6,7],\"pathophysiology\":[6,7,8]}],[\"pode\",415,418,\"I\",{\"history\":[6,7],\"pathophysiology\":[6,7,8]}],[\"ser\",420,422,\"I\",{\"history\":[6,7],\"pathophysiology\":[6,7,8]}],[\"exarcerbada\",424,434,\"I\",{\"history\":[6,7],\"pathophysiology\":[6,7,8]}],[\"diante\",436,441,\"O\",None],[\"de\",443,444,\"O\",None],[\"quadros\",446,452,\"B\",{\"history\":[6,7],\"pathophysiology\":[6,7]}],[\"infecciosos\",454,464,\"I\",{\"history\":[6,7],\"pathophysiology\":[6,7]}],[\"ou\",466,467,\"O\",None],[\"descompensação\",469,482,\"B\",{\"history\":[7],\"pathophysiology\":[7]}],[\"de\",484,485,\"I\",{\"history\":[7],\"pathophysiology\":[7]}],[\"demais\",487,492,\"I\",{\"history\":[7],\"pathophysiology\":[7]}],[\"comorbidades\",494,505,\"I\",{\"history\":[7],\"pathophysiology\":[7]}],[\"e\",507,507,\"O\",None],[\"seu\",509,511,\"O\",None],[\"tratamento\",513,522,\"O\",None],[\"envolve\",524,530,\"O\",None],[\"medidas\",532,538,\"B\",{\"therapeutic\":[12]}],[\"de\",540,541,\"I\",{\"therapeutic\":[12]}],[\"suporte\",543,549,\"I\",{\"therapeutic\":[12]}],[\"com\",551,553,\"O\",None],[\"o2\",555,556,\"B\",{\"therapeutic\":[13,14]}],[\"domiciliar\",558,567,\"I\",{\"therapeutic\":[13,14]}],[\"(\",569,569,\"O\",None],[\"se\",570,571,\"B\",{\"therapeutic\":[14]}],[\"necessário\",573,582,\"I\",{\"therapeutic\":[14]}],[\")\",583,583,\"O\",None]]}\n",
    "# prediction_annotation = eval(model_response[0])\n",
    "def prediction_to_labels(prediction_labels, data_info):\n",
    "    prediction_annotation = eval(prediction_labels[0])\n",
    "    full_text = data_info['text']\n",
    "    text_tokenized = data_info['labels']\n",
    "    categorized_prediction = annotation_to_tokens(full_text, text_tokenized, prediction_annotation)\n",
    "    labels = extract_labels_from_prediction(categorized_prediction)\n",
    "    return categorized_prediction,labels   \n",
    "def truth_to_labels(data_info):\n",
    "    labels = extract_labels_from_truth(data_info['labels'])\n",
    "    return labels\n",
    "def extract_labels_from_truth (data_info):\n",
    "    text_tokenized = data_info\n",
    "    categories = []\n",
    "    for token in text_tokenized:\n",
    "        if token[4] != None:\n",
    "            categories.append(list(token[4].keys()))\n",
    "        else:\n",
    "            categories.append('0')\n",
    "    return categories\n",
    "def annotation_to_tokens (full_text, text_tokenized, prediction_annotation):\n",
    "    clean_text_tokenized = [[token[0],token[1],token[2]] for token in text_tokenized]\n",
    "    annotations = prediction_annotation['annotations']\n",
    "    for annotation in annotations:\n",
    "        # print('============= new annotation', annotation[0])\n",
    "        start_pos = full_text.find(annotation[0])\n",
    "        end_pos = len(annotation[0])+start_pos-1\n",
    "        # print(f'end pos is {len(annotation)} + {start_pos} - 1 = {end_pos}')\n",
    "        categorizing = False\n",
    "        \n",
    "        for token in clean_text_tokenized:\n",
    "            # print(f'token pos {token[1]} annotation pos {start_pos} token {token[0]}')\n",
    "            if token[1] == start_pos:\n",
    "                # print('starting categorization...')\n",
    "                # print(f'start pos {start_pos} end pos {end_pos} token {token[0]}')\n",
    "                categorizing = True\n",
    "            if categorizing:\n",
    "                #adds category to token\n",
    "                # print(f'adding category {annotation[1]} to token {token[0]}')\n",
    "                token.append(annotation[1])\n",
    "                if token[2] == end_pos:\n",
    "                    # print(f'ending categorization at {token[0]}...')\n",
    "                    categorizing = False\n",
    "                    break\n",
    "            \n",
    "            # print(token)\n",
    "    return clean_text_tokenized\n",
    "def extract_labels_from_prediction (categorized_prediction):\n",
    "    labels = []\n",
    "    for token in categorized_prediction:\n",
    "        if len(token) > 3:\n",
    "            labels.append(token[3])\n",
    "        else:\n",
    "            labels.append('0')\n",
    "    return labels   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels of a annotation to binary vector\n",
    "cats = {'pathophysiology':0,\n",
    "        'etiology':1,\n",
    "        'epidemiology':2,\n",
    "        'history':3,\n",
    "        'physical':4,\n",
    "        'exams':5,\n",
    "        'differential':6,\n",
    "        'therapeutic':7}\n",
    "\n",
    "def label2binary(labels):\n",
    "    vet = [0] * 8\n",
    "    # print(vet)\n",
    "    for label in labels:\n",
    "        if label in list(cats.keys()):\n",
    "            vet[cats[label]] = 1\n",
    "    return vet\n",
    "\n",
    "# Convert all the text - divided in tokens - labels to binary vectors\n",
    "def preprocessClassification(text):\n",
    "    for index in range(len(text)):\n",
    "        text[index] = label2binary(text[index])\n",
    "    return text\n",
    "\n",
    "def get_substrings_from_text(text):\n",
    "    substring = text.split(\"\\n\")\n",
    "    return substring\n",
    "\n",
    "def find_complete_text_from_substring(substring, texts):\n",
    "    complete_text = None\n",
    "    count = 0\n",
    "    for text in texts:\n",
    "        if substring[0] in text['text']:\n",
    "            count += 1\n",
    "            complete_text = text\n",
    "        elif substring[0][:100] in text['text']:\n",
    "            count += 1\n",
    "            complete_text = text\n",
    "        elif substring[0].split('.')[0] in text['text']:\n",
    "            count += 1\n",
    "            complete_text = text\n",
    "    if count == 1:\n",
    "        return complete_text\n",
    "    elif count > 1 and len(substring) > 1:\n",
    "        substring.pop(0)\n",
    "        find_complete_text_from_substring(substring, texts)\n",
    "    else:\n",
    "        print('not FOUND', substring[0][:60])\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Here is the output in JSON format: { 'text': 'Mais prevalente em idosos, padrão enfisematoso e bronquitico. Associado a tabagismo, com clínica de tosse, dispneia progressiva, infecções respiratórias, perda de peso. Classicado de acordo com espirometria, pelo VEF1 e CVF, podendo o paciente ser classificado de acordo com nível de síntomas, muito sintomático, pouco sintomático (escalas específicas mMRC e CAT), com exacerbações/internações recentes ou sem muitas exacerbações recentes. Geralmente agudizado com quadros infecciosos, com aumento dos sintomas, mudança no padrão da tosse, febre e outros. Pode se beneficiar de terapia fisioterapia respiratória, vacinação para evitar complicações, sendo indicado de acordo com etapa que se encontra terapia com LAMA, LABA, associação entre ambos, corticoides, azitromicina.', 'annotations': [ ['idosos', ['epidemiology']], ['tabagismo', ['epidemiology', 'etiology']], ['tosse', ['history']], ['dispneia progressiva', ['history']], ['infecções respiratórias', ['history']], ['perda de peso', ['history']], ['espirometria', ['exams']], ['VEF1', ['exams']], ['CVF', ['exams']], ['muito sintomático', ['history']], ['pouco sintomático', ['history']], ['mMRC', ['exams']], ['CAT', ['exams']], ['exacerbações/internações recentes', ['history', 'pathophysiology']], ['quadros infecciosos', ['pathophysiology']], ['aumento dos sintomas', ['history', 'pathophysiology']], ['mudança no padrão da tosse', ['history', 'pathophysiology']], ['febre', ['history', 'pathophysiology']], ['terapia fisioterapia respiratória', ['therapeutic']], ['vacinação', ['therapeutic']], ['LAMA', ['therapeutic']], ['LABA', ['therapeutic']], ['associação entre ambos', ['therapeutic']], ['corticoides', ['therapeutic']], ['azitromicina', ['therapeutic']] ] }\"\n",
    "test2 = \"{ 'annotations': [ ['DPOC', ['history']], ['doença obstrutiva das vias aéreas', ['pathophysiology']], ['tabagistas', ['epidemiology', 'etiology']], ['tórax em barril/tonel', ['physical']], ['sibilos', ['physical']], ['fase expiratória prolongada', ['physical']], ['murmúrio vesicular diminuido', ['physical']], ['dispneia basal', ['history']], ['tosse', ['history']], ['espirometria', ['exams']], ['broncodilatadores', ['therapeutic']] ] }\"\n",
    "def select_after_first_brace(string):\n",
    "    brace_index = string.find(\"{\")\n",
    "    return string[brace_index:]\n",
    "print(select_after_first_brace(test2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#ADDITIONAL BAD DATA real id = 8396380d-e0b6-4b81-8fe9-0b99c611f9f3\n",
    "bad_data = [6,8, 16, 22, 28, 40, 43, 49, 56, 57, 60, 69, 71,72,76,82, 86]\n",
    "\n",
    "# Read the CSV file\n",
    "gabr_test_data = pd.read_csv('../NER/MultiLabel/data_test.csv')\n",
    "gabr_test_data = gabr_test_data.drop(bad_data)\n",
    "# 77c4759b-29f6-4c76-8304-9f5b186d28d1\n",
    "test_data_info = []\n",
    "\n",
    "for text in gabr_test_data['Text']:\n",
    "    complete_text = find_complete_text_from_substring(get_substrings_from_text(text), annotated_dataset)\n",
    "    if complete_text != None:\n",
    "        test_data_info.append(complete_text)\n",
    "df_test_data_info = pd.DataFrame(test_data_info)\n",
    "df_test_data_info = df_test_data_info.drop(df_test_data_info.columns.difference(['doc_id', 'text', 'labels']), axis=1)\n",
    "\n",
    "df_test_data_info.to_csv('test_data_info.csv', index=False)\n",
    "\n",
    "\n",
    "# find_complete_text_from_substring(get_substrings_from_text(), # find_complete_text_from_substring(get_substrings_from_text(), annotated_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = \"77c4759b-29f6-4c76-8304-9f5b186d28d1\"\n",
    "row = df_test_data_info[df_test_data_info['doc_id'] == '77c4759b-29f6-4c76-8304-9f5b186d28d1']\n",
    "df_copy = df_test_data_info.copy()\n",
    "\n",
    "df_copy['prediction'] = ''\n",
    "df_copy.loc[df_copy['doc_id'] == '77c4759b-29f6-4c76-8304-9f5b186d28d1', 'prediction'] = 'aaa'\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_vector = preprocessClassification(labels.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Excluding data without annotations and small text\n",
    "annotated_dataset = get_examples('../teste-progresso/04-ml/annotations-medical_specialist-dpoc-bio-composed-multiple.jsonl')\n",
    "bad_lines = []\n",
    "for line in annotated_dataset:\n",
    "    if len(line['text']) < 30:\n",
    "        print(line['doc_id'], 'is too small')\n",
    "        bad_lines.append(line)\n",
    "    elif len(line['labels']) < 1:\n",
    "        print(line['labels'])\n",
    "        print(line['doc_id'], 'has no annotations')\n",
    "        bad_lines.append(line)\n",
    "\n",
    "\n",
    "for line in bad_lines:\n",
    "    print('removing line...',line)\n",
    "    annotated_dataset.remove(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\b\\w+([-]\\w+)*\\b|\\w+|\\S'\n",
    "text = 'pesado/fogão à lenha'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert annotated_dataset to DataFrame\n",
    "df_annotated_dataset = pd.DataFrame(annotated_dataset)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_annotated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated_dataset.to_csv('annotated_dataset_dpoc_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_data = [6,8, 16, 22, 28, 40, 43, 49, 56, 57, 60, 69, 71,72,76,82, 86]\n",
    "\n",
    "# Read the CSV file\n",
    "gabr_test_data = pd.read_csv('test_data_info.csv')\n",
    "# gabr_test_data = gabr_test_data.drop(bad_data)\n",
    "# 77c4759b-29f6-4c76-8304-9f5b186d28d1\n",
    "test_data_info = []\n",
    "\n",
    "for line in gabr_test_data['text']:\n",
    "    if len(line) > 30:\n",
    "        complete_text = find_complete_text_from_substring(get_substrings_from_text(line), annotated_dataset)\n",
    "        if complete_text != None:\n",
    "            test_data_info.append(complete_text)\n",
    "            print(line)\n",
    "            print(complete_text,'\\n=================')\n",
    "print(test_data_info)\n",
    "df_test_data_info = pd.DataFrame(test_data_info)\n",
    "df_test_data_info = df_test_data_info.drop(df_test_data_info.columns.difference(['doc_id', 'text', 'labels']), axis=1)\n",
    "df_test_data_info\n",
    "df_test_data_info.to_csv('test_data_info_no_short.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'test_data_info_no_short.csv'\n",
    "df_data_info = pd.read_csv(file_name)\n",
    "def minimize_labels(label):\n",
    "    n_label = []\n",
    "    if type(label) == str:\n",
    "        label = eval(label)\n",
    "    for l in label:\n",
    "        if l[4] != None:\n",
    "            n_label.append([l[0],list(l[4].keys())])\n",
    "        else:\n",
    "            n_label.append([l[0],l[4]])\n",
    "    return n_label\n",
    "def get_only_text(label):\n",
    "    n_label = []\n",
    "    if type(label) == str:\n",
    "        label = eval(label)\n",
    "    for l in label:\n",
    "        n_label.append([l[0]])\n",
    "    return n_label\n",
    "\n",
    "def bio_to_cluster_annotation(bio_annotation):\n",
    "    main_annotation = []\n",
    "    if type(bio_annotation) == str:\n",
    "        list_ann = eval(bio_annotation)\n",
    "    else:\n",
    "        list_ann = bio_annotation\n",
    "    sub_annotation = []\n",
    "    phrase = []\n",
    "    for z in range(len(list_ann)):\n",
    "        print(f\"  Token {z}: {list_ann[z]}\")\n",
    "        if list_ann[z][3] == 'B':\n",
    "            if len(phrase) > 0:\n",
    "                sub_annotation.append([' '.join(phrase), list(current_category.keys()) if current_category is not None else None])\n",
    "                phrase = []\n",
    "            phrase.append(list_ann[z][0])\n",
    "        elif list_ann[z][3] == 'I':\n",
    "            current_category = list_ann[z][4]\n",
    "            phrase.append(list_ann[z][0])\n",
    "        print(list_ann[z])\n",
    "        if z == len(list_ann):\n",
    "            break\n",
    "    # Append last phrase if exists\n",
    "    if len(phrase) > 0:\n",
    "        sub_annotation.append([' '.join(phrase), list(list_ann[-1][4].keys()) if list_ann[-1][4] is not None else None])\n",
    "    main_annotation.append(sub_annotation)\n",
    "    return main_annotation\n",
    "\n",
    "def insert_augmented_annotations_into_text(text, annotations):\n",
    "    diff_pos = 0\n",
    "    for ann in annotations:\n",
    "        start_pos = ann[1] + diff_pos\n",
    "        end_pos = ann[2] + diff_pos\n",
    "        entity = ann[0]\n",
    "        # augmented_entity = f'[{entity} | {\", \".join(ann[3])}]'\n",
    "        text = text[:start_pos] + entity + text[end_pos+1:]\n",
    "        diff_pos += len(entity) - (end_pos - start_pos + 1)\n",
    "    return text\n",
    "def replace_line_breaks(text):\n",
    "    return text.replace('\\n', '\\\\n')\n",
    "def bio_to_augmented_annotation(annotation_data):\n",
    "    bio_annotation = annotation_data['labels']\n",
    "    text_source = annotation_data['text']\n",
    "    print(text_source)\n",
    "    main_annotation = []\n",
    "    for i in range(len(bio_annotation)):\n",
    "        # print(annotation_data['doc_id'][i],'=======================')\n",
    "        if type(bio_annotation[i]) == str:\n",
    "            list_ann = eval(bio_annotation)\n",
    "        else:\n",
    "            list_ann = bio_annotation\n",
    "        \n",
    "        sub_annotation = []\n",
    "        phrase = []\n",
    "        initial_pos = 0\n",
    "        final_pos = 0\n",
    "        for z in range(len(list_ann)):\n",
    "            if list_ann[z][3] == 'B':\n",
    "                if len(phrase) > 0:\n",
    "                    print(' '.join(phrase),list(list_ann[z][4].keys()))\n",
    "                    if ' '.join(phrase) != text_source[i][initial_pos:final_pos]:\n",
    "                        \n",
    "                        print('finding phrase in text...',phrase, initial_pos,final_pos)\n",
    "                        print(' '.join(phrase),text_source[i].find(' '.join(phrase)),len(' '.join(phrase))+text_source[i].find(' '.join(phrase)))\n",
    "                        print(f'===={text_source[i][initial_pos:final_pos]}======')\n",
    "                    augmented_entity = f'[{text_source[i][initial_pos:final_pos]} | {\", \".join(current_category.keys())}]'\n",
    "                    joint_phrase = ''\n",
    "                    for token in phrase:\n",
    "                        if token not in [',', '.', ';', ':', '!', '?', '\"', \"'\", '(', ')']:\n",
    "                            if token != phrase[-1]:\n",
    "                                joint_phrase += token+' '\n",
    "                            else:\n",
    "                                joint_phrase += token\n",
    "                        else:\n",
    "                            joint_phrase = joint_phrase[:-1]+token+' '\n",
    "                    if joint_phrase != text_source[i][initial_pos:final_pos]:\n",
    "                        print('============= ERRORRR ======')\n",
    "                        print('finding phrase in text...',phrase, initial_pos,final_pos)\n",
    "                        print(' '.join(phrase),text_source[i].find(' '.join(phrase)),len(' '.join(phrase))+text_source[i].find(' '.join(phrase)))\n",
    "                        print(f'===={text_source[i][initial_pos:final_pos]}======')\n",
    "                    sub_annotation.append([augmented_entity,initial_pos,final_pos])\n",
    "                    phrase = []\n",
    "                \n",
    "                initial_pos = list_ann[z][1]\n",
    "                final_pos = list_ann[z][2]+1\n",
    "                phrase.append(list_ann[z][0])\n",
    "            elif list_ann[z][3] == 'I':\n",
    "                current_category = list_ann[z][4]\n",
    "                final_pos = list_ann[z][2]+1\n",
    "                phrase.append(list_ann[z][0])\n",
    "        # print(text_source[i])\n",
    "        # print(insert_augmented_annotations_into_text(text_source[i], sub_annotation))\n",
    "        # print(bio_annotation[i],'\\n\\n')\n",
    "        main_annotation.append(insert_augmented_annotations_into_text(text_source[i], sub_annotation))\n",
    "    return main_annotation\n",
    "def extract_example_shot_from_row(_row, output='string'):\n",
    "    if output == 'list':\n",
    "        shot_text = {'user_input':_row['text'],'assistant_output':_row['cluster_labels']}\n",
    "    elif output == 'string':\n",
    "        shot_text = f\"\"\"'user_input':{_row['text']}\\n 'assistant_output':{_row['cluster_labels']}\"\"\"\n",
    "    return shot_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### BIO FORMAT to AUGMENTED FORMAT for few-shot ##########################################################\n",
    "file_name = 'annotations_medical_specialist_pre_processed.csv'\n",
    "complete_df = pd.read_csv(file_name)\n",
    "\n",
    "\n",
    "augmented_annotations = bio_to_augmented_annotation(complete_df)\n",
    "\n",
    "complete_df['augmented_annotation'] = augmented_annotations\n",
    "\n",
    "# for index, row in df_data_info.iterrows():\n",
    "    # print(row['text'])\n",
    "    # print(row['augmented_annotation'])\n",
    "    # # print(row['cluster_labels'])\n",
    "    # print(row['labels'])\n",
    "    # print('=====================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"Está relacionada com um indivíduo mais velho, geralmente tabagista (ou ex-tabagista de longa data) e/ou bronquiticos crônicos e/ou trabalhador em minas de carvão, olaria e outras ocupações que envolvem aspiração de partículas tóxicas para o parênquima pulmonar. Os sintomas surgem insidiosamente e progridem lentamente à medida em que os agressores continuam atuando nos pulmões.\\nDiminuição da capacidade funcional pulmonar, dispneia,\"\"\"\n",
    "test2 = \"\"\"Está relacionada com um indivíduo mais velho, geralmente tabagista (ou ex-tabagista de longa data) e/ou bronquiticos crônicos e/ou trabalhador em minas de carvão, olaria e outras ocupações que envolvem aspiração de partículas tóxicas para o parênquima pulmonar. Os sintomas surgem insidiosamente e progridem lentamente à medida em que os agressores continuam atuando nos pulmões.\\nDiminuição da capacidade funcional pulmonar, dispneia, baixa saturação ao oxímetro de pulso, falta de ar aos pequenos esforços, baqueteamento digital, unhas em \"vidro fosco\", cianose central e até periférica são importantes achados\\n\"\"\"\n",
    "print(test[380:423])\n",
    "print(test2[380:423])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your dataframe\n",
    "df = df[df['precision'] != 0]\n",
    "df = df[df['precision'].apply(lambda x: x[0] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_annotations = bio_to_cluster_annotation(df_data_info['labels'])\n",
    "df_data_info['minimized_labels'] = df_data_info['labels'].apply(lambda x: minimize_labels(x))\n",
    "df_data_info['cluster_labels'] = cluster_annotations\n",
    "df_data_info.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1, 2, 3, 4, 5]\n",
    "list2 = [4, 5, 6, 7, 8]\n",
    "\n",
    "diff = list(set(list1) - set(list2))\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######  ADDING THE CLUSTER LABELS TO THE annotations-medical_specialist-dpoc-bio-composed-multiple FILE\n",
    "\n",
    "complete_file_path = '../teste-progresso/04-ml/annotations-medical_specialist-dpoc-bio-composed-multiple.jsonl'\n",
    "test_full_text = '../teste-progresso/04-ml/annotations-medical_specialist-dpoc-full.jsonl'\n",
    "full_text_dict = []\n",
    "with open(test_full_text, 'r',encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        full_text_dict.append(json.loads(line))\n",
    "complete_df_medical_specialist_dict = get_examples(complete_file_path)\n",
    "print(type(complete_df_medical_specialist_dict))\n",
    "print(complete_df_medical_specialist_dict[0])\n",
    "complete_df_medical_specialist = pd.DataFrame(complete_df_medical_specialist_dict)\n",
    "print(type(complete_df_medical_specialist))\n",
    "cluster_annotations_medical_specialist = bio_to_cluster_annotation(complete_df_medical_specialist['labels'])\n",
    "complete_df_medical_specialist['minimized_labels'] = complete_df_medical_specialist['labels'].apply(lambda x: minimize_labels(x))\n",
    "complete_df_medical_specialist['cluster_labels'] = cluster_annotations_medical_specialist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from jsonl_data with doc_id as key and text as value\n",
    "full_text_dict = {item['doc_id']: item['text'] for item in full_text_dict}\n",
    "\n",
    "# Replace the text column in csv_data with the text from jsonl_data\n",
    "complete_df_medical_specialist['text'] = complete_df_medical_specialist['doc_id'].map(full_text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df_medical_specialist['text'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df_medical_specialist = complete_df_medical_specialist[complete_df_medical_specialist['text'].apply(lambda x: len(x) >= 30)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df_medical_specialist.to_csv('annotations_medical_specialist_pre_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_substrings_from_text(text):\n",
    "    substring = text.split(\"\\n\")\n",
    "    return substring\n",
    "\n",
    "def find_complete_text_from_substring(substring, texts):\n",
    "    complete_text = None\n",
    "    count = 0\n",
    "    for text in texts:\n",
    "        if substring[0] in text['text']:\n",
    "            count += 1\n",
    "            complete_text = text\n",
    "        elif substring[0][:100] in text['text']:\n",
    "            count += 1\n",
    "            complete_text = text\n",
    "        elif substring[0].split('.')[0] in text['text']:\n",
    "            count += 1\n",
    "            complete_text = text\n",
    "    if count == 1:\n",
    "        return complete_text\n",
    "    elif count > 1 and len(substring) > 1:\n",
    "        substring.pop(0)\n",
    "        find_complete_text_from_substring(substring, texts)\n",
    "    else:\n",
    "        print('not FOUND', substring[0][:60])\n",
    "        return None\n",
    "    \n",
    "full_data_teste_progresso = pd.read_csv('annotations_medical_specialist_pre_processed.csv')\n",
    "# gabr_test_data = gabr_test_data.drop(bad_data)\n",
    "# 77c4759b-29f6-4c76-8304-9f5b186d28d1\n",
    "\n",
    "for index, row in full_data_teste_progresso.iterrows():\n",
    "    if len(row['text']) < 30:\n",
    "        full_data_teste_progresso.drop([index])\n",
    "    if len(eval(row['cluster_labels'])) < 1:\n",
    "        full_data_teste_progresso = full_data_teste_progresso.drop([index])\n",
    "full_data_teste_progresso.to_csv('annotations_medical_specialist_pre_processed_no_short.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testeee = pd.read_csv('annotations_medical_specialist_pre_processed_no_short.csv')\n",
    "first_row = testeee.iloc[0]\n",
    "clusterr = bio_to_augmented_annotation(first_row)\n",
    "print(clusterr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def compare_document_annotations(doc1, doc2):\n",
    "    \"\"\"\n",
    "    Compares two documents with annotations to find differences in categories\n",
    "    and unique annotations.\n",
    "\n",
    "    The expected format for the input documents is a list of lists, where each\n",
    "    inner list contains an annotation string and a list of its categories.\n",
    "    Example: [['annotation_text', ['category1', 'category2']]]\n",
    "\n",
    "    Args:\n",
    "        doc1 (list): A list of annotations for the first document.\n",
    "        doc2 (list): A list of annotations for the second document.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with three keys:\n",
    "              'different_categories': A list of annotations present in both\n",
    "                                      documents but with differing categories.\n",
    "              'only_in_doc1': A list of annotations found only in the first\n",
    "                              document.\n",
    "              'only_in_doc2': A list of annotations found only in the second\n",
    "                              document.\n",
    "    \"\"\"\n",
    "    annotations_doc1 = {item[0]: set(item[1]) if item[1] is not None else set() for item in doc1}\n",
    "    annotations_doc2 = {item[0]: set(item[1]) if item[1] is not None else set() for item in doc2}\n",
    "\n",
    "    all_annotations = set(annotations_doc1.keys()) | set(annotations_doc2.keys())\n",
    "\n",
    "    comparison_results = {\n",
    "        'different_categories': [],\n",
    "        'only_in_doc1': [],\n",
    "        'only_in_doc2': []\n",
    "    }\n",
    "\n",
    "    for annotation in sorted(list(all_annotations)):\n",
    "        is_in_doc1 = annotation in annotations_doc1\n",
    "        is_in_doc2 = annotation in annotations_doc2\n",
    "\n",
    "        if is_in_doc1 and is_in_doc2:\n",
    "            if annotations_doc1[annotation] != annotations_doc2[annotation]:\n",
    "                comparison_results['different_categories'].append({\n",
    "                    \"annotation\": annotation,\n",
    "                    \"doc1_categories\": sorted(list(annotations_doc1[annotation])),\n",
    "                    \"doc2_categories\": sorted(list(annotations_doc2[annotation]))\n",
    "                })\n",
    "        elif is_in_doc1:\n",
    "            comparison_results['only_in_doc1'].append({\n",
    "                \"annotation\": annotation,\n",
    "                \"categories\": sorted(list(annotations_doc1[annotation]))\n",
    "            })\n",
    "        elif is_in_doc2:\n",
    "            comparison_results['only_in_doc2'].append({\n",
    "                \"annotation\": annotation,\n",
    "                \"categories\": sorted(list(annotations_doc2[annotation]))\n",
    "            })\n",
    "\n",
    "    return comparison_results\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# Annotations for the first document\n",
    "document1_annotations = [\n",
    "    ['enfisema pulmonar', ['pathophysiology', 'physical']],\n",
    "    ['brônquite crônica', ['pathophysiology', 'physical']],\n",
    "    ['Associado fortemente', ['epidemiology']],\n",
    "    ['tabagismo', ['epidemiology']],\n",
    "    ['Não há cura', ['pathophysiology', 'therapeutic']],\n",
    "    ['melhora dos hábitos', ['therapeutic']],\n",
    "    ['aliviar os sintomas', ['therapeutic']],\n",
    "    ['melhorar a função respiratória', ['therapeutic']],\n",
    "    ['fator de risco para outras doenças pulmonares', ['epidemiology', 'pathophysiology']],\n",
    "    ['pneumonia', None]\n",
    "]\n",
    "\n",
    "# Annotations for the second document (with variations for comparison)\n",
    "document2_annotations = [\n",
    "    ['enfisema pulmonar', ['pathophysiology']],  # Category is different\n",
    "    ['brônquite crônica', ['pathophysiology', 'physical']], # Identical annotation\n",
    "    ['tabagismo', ['epidemiology', 'risk_factor']], # Category is different\n",
    "    ['Não há cura', ['prognosis']], # Category is different\n",
    "    ['melhora dos hábitos', ['therapeutic', 'lifestyle']], # Category is different\n",
    "    ['aliviar os sintomas', ['therapeutic']], # Identical annotation\n",
    "    ['doença pulmonar obstrutiva crônica', ['pathophysiology']], # New annotation\n",
    "    ['dispneia', ['symptom']] # New annotation\n",
    "]\n",
    "\n",
    "# Perform the comparison\n",
    "differences_found = compare_document_annotations(document1_annotations, document2_annotations)\n",
    "\n",
    "# Display the results\n",
    "print(\"Comparison of Document Annotations\")\n",
    "print(\"====================================\")\n",
    "\n",
    "print(\"\\nAnnotations with Different Categories:\")\n",
    "if differences_found['different_categories']:\n",
    "    for difference in differences_found['different_categories']:\n",
    "        print(f\"  - Annotation: \\\"{difference['annotation']}\\\"\")\n",
    "        print(f\"    - Document 1 Categories: {difference['doc1_categories']}\")\n",
    "        print(f\"    - Document 2 Categories: {difference['doc2_categories']}\")\n",
    "else:\n",
    "    print(\"  No annotations with different categories were found.\")\n",
    "\n",
    "print(\"\\nAnnotations Found Only in Document 1:\")\n",
    "if differences_found['only_in_doc1']:\n",
    "    for item in differences_found['only_in_doc1']:\n",
    "        print(f\"  - Annotation: \\\"{item['annotation']}\\\" (Categories: {item['categories']})\")\n",
    "else:\n",
    "    print(\"  No unique annotations were found in Document 1.\")\n",
    "\n",
    "print(\"\\nAnnotations Found Only in Document 2:\")\n",
    "if differences_found['only_in_doc2']:\n",
    "    for item in differences_found['only_in_doc2']:\n",
    "        print(f\"  - Annotation: \\\"{item['annotation']}\\\" (Categories: {item['categories']})\")\n",
    "else:\n",
    "    print(\"  No unique annotations were found in Document 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_bio_annotations(data):\n",
    "    \"\"\"\n",
    "    Augments the text in a dictionary with BIO-tagged annotations.\n",
    "\n",
    "    Args:\n",
    "      data: A dictionary with 'text' and 'labels' keys.\n",
    "            'text' contains the original text.\n",
    "            'labels' is a list of lists, where each inner list represents\n",
    "                     a token with its text, start, end, BIO tag, and\n",
    "                     an optional dictionary of annotations.\n",
    "\n",
    "    Returns:\n",
    "      The dictionary with an added 'augmented_annotation' key\n",
    "      containing the augmented text.\n",
    "    \"\"\"\n",
    "    text = data['text']\n",
    "    labels = data['labels']\n",
    "    augmented_text = text[:]  # Create a copy to modify\n",
    "\n",
    "    annotated_phrases = []\n",
    "    current_phrase = \"\"\n",
    "    current_labels = set()\n",
    "    \n",
    "    if type(labels) is str:\n",
    "        labels = eval(labels)\n",
    "    for i, label_info in enumerate(labels):\n",
    "        token_text = label_info[0]\n",
    "        tag = label_info[3]\n",
    "        annotations = label_info[4]\n",
    "\n",
    "        if tag == 'B':\n",
    "            if current_phrase:\n",
    "                annotated_phrases.append((current_phrase.strip(), list(current_labels)))\n",
    "            current_phrase = token_text\n",
    "            current_labels = set(annotations.keys()) if annotations else set()\n",
    "        elif tag == 'I' and current_phrase:\n",
    "            # We need to check if the current token is part of the same phrase.\n",
    "            # This can be done by checking if the start position of the current token\n",
    "            # is close to the end position of the previous token.\n",
    "            prev_end_pos = labels[i-1][2]\n",
    "            current_start_pos = label_info[1]\n",
    "            # A simple check for adjacency or separated by a single space\n",
    "            if current_start_pos - prev_end_pos <= 2:\n",
    "                 current_phrase += \" \" + token_text\n",
    "            else: # If it's not adjacent, it's a new phrase starting with 'I' (less common but possible)\n",
    "                if current_phrase:\n",
    "                    annotated_phrases.append((current_phrase.strip(), list(current_labels)))\n",
    "                current_phrase = token_text\n",
    "                current_labels = set(annotations.keys()) if annotations else set()\n",
    "\n",
    "            if annotations:\n",
    "                current_labels.update(annotations.keys())\n",
    "        elif tag == 'O':\n",
    "            if current_phrase:\n",
    "                annotated_phrases.append((current_phrase.strip(), list(current_labels)))\n",
    "                current_phrase = \"\"\n",
    "                current_labels = set()\n",
    "\n",
    "    if current_phrase:\n",
    "        annotated_phrases.append((current_phrase.strip(), list(current_labels)))\n",
    "\n",
    "    # Replace the phrases in the text\n",
    "    for phrase, phrase_labels in annotated_phrases:\n",
    "        if phrase_labels:\n",
    "            formatted_labels = \", \".join(sorted(list(set(phrase_labels))))\n",
    "            replacement = f\"[{phrase} | {formatted_labels}]\"\n",
    "            augmented_text = augmented_text.replace(phrase, replacement)\n",
    "\n",
    "    data['augmented_annotation'] = augmented_text\n",
    "    return augmented_text\n",
    "\n",
    "# Input dictionary with the new annotation format\n",
    "input_data_bio = {\n",
    "    'text': \"Relacionada com enfisema pulmonar e brônquite crônica. Associado fortemente ao tabagismo. Não há cura, o que há é tratamento com tentativa de melhora dos hábitos para aliviar os sintomas e melhorar a função respiratória. DPOC pode ser fator de risco para outras doenças pulmonares, como pneumonia.\",\n",
    "    'labels': [['Relacionada', 0, 10, 'O', None], ['com', 12, 14, 'O', None], ['enfisema', 16, 23, 'B', {'pathophysiology': [1], 'physical': [1]}], ['pulmonar', 25, 32, 'I', {'pathophysiology': [1], 'physical': [1]}], ['e', 34, 34, 'O', None], ['brônquite', 36, 44, 'B', {'pathophysiology': [2], 'physical': [2]}], ['crônica', 46, 52, 'I', {'pathophysiology': [2], 'physical': [2]}], ['.', 53, 53, 'O', None], ['Associado', 55, 63, 'B', {'epidemiology': [5, 6]}], ['fortemente', 65, 74, 'I', {'epidemiology': [5, 6]}], ['ao', 76, 77, 'O', None], ['tabagismo', 79, 87, 'B', {'epidemiology': [5, 6]}], ['.', 88, 88, 'O', None], ['Não', 90, 92, 'B', {'pathophysiology': [7], 'therapeutic': [7]}], ['há', 94, 95, 'I', {'pathophysiology': [7], 'therapeutic': [7]}], ['cura', 97, 100, 'I', {'pathophysiology': [7], 'therapeutic': [7]}], [',', 101, 101, 'O', None], ['o', 103, 103, 'O', None], ['que', 105, 107, 'O', None], ['há', 109, 110, 'O', None], ['é', 112, 112, 'O', None], ['tratamento', 114, 123, 'O', None], ['com', 125, 127, 'O', None], ['tentativa', 129, 137, 'O', None], ['de', 139, 140, 'O', None], ['melhora', 142, 148, 'B', {'therapeutic': [8]}], ['dos', 150, 152, 'I', {'therapeutic': [8]}], ['hábitos', 154, 160, 'I', {'therapeutic': [8]}], ['para', 162, 165, 'O', None], ['aliviar', 167, 173, 'B', {'therapeutic': [9]}], ['os', 175, 176, 'I', {'therapeutic': [9]}], ['sintomas', 178, 185, 'I', {'therapeutic': [9]}], ['e', 187, 187, 'O', None], ['melhorar', 189, 196, 'B', {'therapeutic': [10]}], ['a', 198, 198, 'I', {'therapeutic': [10]}], ['função', 200, 205, 'I', {'therapeutic': [10]}], ['respiratória', 207, 218, 'I', {'therapeutic': [10]}], ['.', 219, 219, 'O', None], ['DPOC', 221, 224, 'O', None], ['pode', 226, 229, 'O', None], ['ser', 231, 233, 'O', None], ['fator', 235, 239, 'B', {'epidemiology': [3, 4], 'pathophysiology': [3, 4]}], ['de', 241, 242, 'I', {'epidemiology': [3, 4], 'pathophysiology': [3, 4]}], ['risco', 244, 248, 'I', {'epidemiology': [3, 4], 'pathophysiology': [3, 4]}], ['para', 250, 253, 'I', {'epidemiology': [3, 4], 'pathophysiology': [3, 4]}], ['outras', 255, 260, 'I', {'epidemiology': [3, 4], 'pathophysiology': [3, 4]}], ['doenças', 262, 268, 'I', {'epidemiology': [3, 4], 'pathophysiology': [3, 4]}], ['pulmonares', 270, 279, 'I', {'epidemiology': [3, 4], 'pathophysiology': [3, 4]}], [',', 280, 280, 'O', None], ['como', 282, 285, 'O', None], ['pneumonia', 287, 295, 'B', {'epidemiology': [4], 'pathophysiology': [4]}], ['.', 296, 296, 'O', None]]\n",
    "}\n",
    "\n",
    "# Process the data\n",
    "augmented_data_bio = augment_bio_annotations(first_row)\n",
    "\n",
    "# Print the augmented text\n",
    "print(augmented_data_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_file_path = '../teste-progresso/04-ml/annotations-medical_specialist-dpoc-bio-composed-multiple.jsonl'\n",
    "# test_full_text = '../teste-progresso/04-ml/annotations-medical_specialist-dpoc-full.jsonl'\n",
    "full_text_dict = []\n",
    "with open(complete_file_path, 'r',encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        full_text_dict.append(json.loads(line))\n",
    "complete_df_medical_specialist_dict = get_examples(complete_file_path)\n",
    "print(type(complete_df_medical_specialist_dict))\n",
    "print(complete_df_medical_specialist_dict[0])\n",
    "complete_df_medical_specialist = pd.DataFrame(complete_df_medical_specialist_dict)\n",
    "print(type(complete_df_medical_specialist))\n",
    "cluster_annotations_medical_specialist = bio_to_cluster_annotation(complete_df_medical_specialist['labels'])\n",
    "complete_df_medical_specialist['minimized_labels'] = complete_df_medical_specialist['labels'].apply(lambda x: minimize_labels(x))\n",
    "complete_df_medical_specialist['cluster_labels'] = cluster_annotations_medical_specialist\n",
    "complete_df_medical_specialist = complete_df_medical_specialist[complete_df_medical_specialist['text'].apply(lambda x: len(x) >= 30)]\n",
    "complete_df_medical_specialist.to_csv('annotations_medical_specialist_pre_processed_fixing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fixing = pd.read_csv('annotations_medical_specialist_pre_processed_fixing.csv')\n",
    "df_original = pd.read_csv('annotations_medical_specialist_pre_processed.csv')\n",
    "# Compare the two DataFrames\n",
    "compare_document_annotations(df_fixing['cluster_labels'].tolist(), df_original['cluster_labels'].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
